<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Statistical Modelling - 2&nbsp; Regression analysis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./pca.html" rel="next">
<link href="./intro.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regression.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Regression analysis</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Statistical Modelling</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Regression analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pca.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Principal component analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pca-applications.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Applications of principal component analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datasets.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Datasets</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#the-linear-regression-model" id="toc-the-linear-regression-model" class="nav-link active" data-scroll-target="#the-linear-regression-model"><span class="header-section-number">2.1</span> The linear regression model</a></li>
  <li><a href="#the-residual-standard-deviation" id="toc-the-residual-standard-deviation" class="nav-link" data-scroll-target="#the-residual-standard-deviation"><span class="header-section-number">2.2</span> The residual standard deviation</a></li>
  <li><a href="#deviations-from-the-assumptions-in-linear-regression-analysis" id="toc-deviations-from-the-assumptions-in-linear-regression-analysis" class="nav-link" data-scroll-target="#deviations-from-the-assumptions-in-linear-regression-analysis"><span class="header-section-number">2.3</span> Deviations from the assumptions in linear regression analysis</a></li>
  <li><a href="#inference-in-regression-models" id="toc-inference-in-regression-models" class="nav-link" data-scroll-target="#inference-in-regression-models"><span class="header-section-number">2.4</span> Inference in regression models</a></li>
  <li><a href="#the-multiple-correlation-coefficient" id="toc-the-multiple-correlation-coefficient" class="nav-link" data-scroll-target="#the-multiple-correlation-coefficient"><span class="header-section-number">2.5</span> The multiple correlation coefficient</a></li>
  <li><a href="#multiple-linear-regression" id="toc-multiple-linear-regression" class="nav-link" data-scroll-target="#multiple-linear-regression"><span class="header-section-number">2.6</span> Multiple linear regression</a></li>
  <li><a href="#inference-in-regression-models-and-model-construction" id="toc-inference-in-regression-models-and-model-construction" class="nav-link" data-scroll-target="#inference-in-regression-models-and-model-construction"><span class="header-section-number">2.7</span> Inference in regression models and model construction</a></li>
  <li><a href="#regression-diagnostics" id="toc-regression-diagnostics" class="nav-link" data-scroll-target="#regression-diagnostics"><span class="header-section-number">2.8</span> Regression diagnostics</a>
  <ul class="collapse">
  <li><a href="#multicollinearity" id="toc-multicollinearity" class="nav-link" data-scroll-target="#multicollinearity"><span class="header-section-number">2.8.1</span> Multicollinearity</a></li>
  <li><a href="#influential-observations" id="toc-influential-observations" class="nav-link" data-scroll-target="#influential-observations"><span class="header-section-number">2.8.2</span> Influential observations</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Regression analysis</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Often a lot of measurements for each subject (e.g., each animal or each plant) are collected in scientific experiments in biosciences. An ecologist could, for example, measure at the same time the number of a certain shrub on different plots of land, as well as the acidity of each plot in order to hopefully be able to describe a relationship between both. A biotechnologist might be interested in seeing which genes are important during which phase of the growth of a plant. He or she could therefore collect at appropriate times measurements for the expression of different genes and subsequently investigate the association between gene expression and time. The purpose of this chapter is to provide techniques to detect patterns and relations in complex datasets and then to use these relations to predict future outcomes. We will in particular focus on situations where we are interested in one specific continuous outcome and hope to understand its relationship with one or more continuous or qualitative variables.</p>
<section id="the-linear-regression-model" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="the-linear-regression-model"><span class="header-section-number">2.1</span> The linear regression model</h2>
<p>Although the correlation coefficient is frequently used in explorative and descriptive statistics to describe an association between 2 continuous measurements, it has a number of limitations:</p>
<ol type="1">
<li>Its numerical value is difficult to interpret;</li>
<li>It cannot be used to predict the value of the outcome <span class="math inline">\(Y\)</span> (e.g., the number of nests of red land crabs in a certain area) based on some predictor value <span class="math inline">\(X\)</span> (e.g., the biomass of crabs in that area);</li>
<li>It does not allow for an easy correction of the association between the variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> for the disturbing influence of measured confounders;</li>
<li>It does not allow for an easy verification of whether the strength of the association between the variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> depends on the value of a third variable <span class="math inline">\(Z\)</span> (e.g., to verify if there exist gene-neighbourhood interactions where the influence that certain genes exert on the development of Chronic Obstructive Pulmonary Disease depends on smoking history);</li>
<li>It does not allow to describe nonlinear associations or associations between a continuous and a qualitative variable.</li>
</ol>
<p>To handle these problems in a flexible way, we will use regression techniques.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example: Woody debris and tree density
</div>
</div>
<div class="callout-body-container callout-body">
<p>The human impact on freshwater environments concerns scientists a lot. Coarse woody debris (CWD) is fallen wood that provides a habitat for aquatic organisms and furthermore influences hydrological processes and the transport of organic materials within aquatic ecosystems. The presence of humans has altered the CWD input to aquatic systems. Chistensen et al.&nbsp;(1996) (TODO fix up reference) studied the connection between coarse woody debris and riparian vegetation in a sample of 16 North American lakes. They defined CWD as woody debris with a diameter larger than 5 cm and registered for a number of locations along the shoreline the CWD basal area (in m<span class="math inline">\(^2\)</span> per km of shoreline) and the tree density (in number per km of shoreline). To obtain a single measurement per lake, weighted averages were used.</p>
<p>The goal of this study is to describe the association between the tree density along the shoreline of the lake and the relative basal area of CWD. Since we want to explain the effect of the tree density on CWD, we call tree density the <em>explanatory</em>, <em>predictor</em> or <em>independent variable</em> and the CWD basal area the <em>outcome</em> or <em>dependent variable</em>, i.e., the variable in which we are primarily interested. For the rest of this section, we will always use <span class="math inline">\(X\)</span> for the independent variables and <span class="math inline">\(Y\)</span> for the dependent variables.</p>
<p><a href="#fig-trees" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> plots the CWD basal area (in m<span class="math inline">\(^2\)</span> per km) in function of the riparian tree density, together with a loess scatterplot smoother (dotted line). The plot gives no indication that the relation between both variables would not be linear. Hence the Pearson correlation coefficient is an appropriate measure. It is equal to 0.797, which suggests a strong increase in CWD basal area with an increased riparian tree density. We gain more insight in the strength of the association by studying the loess scatterplot smoother, since this function gives for every tree density value the expected outcome for the CWD basal area. Because this curve can be well approximated by a much simpler, linear relation, we also added the `best fitting’ straight line (full line; i.e., the least squares regression line) to the plot. This gives an even clearer image of the relationship between both variables than the correlation coefficient, and also uses only 1 parameter (namely the slope) to do so. In this section we will see how to construct and interpret this so-called regression line.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>trees <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"./datasets/01-regression/christ.csv"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(CWD.BASA <span class="sc">~</span> RIP.DENS, <span class="at">data =</span> trees,</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Riparian tree density"</span>,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"CWD basal area"</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(CWD.BASA <span class="sc">~</span> RIP.DENS, <span class="at">data =</span> trees)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m1)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">loess</span>(CWD.BASA <span class="sc">~</span> RIP.DENS, <span class="at">data =</span> trees)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>j <span class="ot">&lt;-</span> <span class="fu">order</span>(trees<span class="sc">$</span>RIP.DENS)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(trees<span class="sc">$</span>RIP.DENS[j], m2<span class="sc">$</span>fitted[j], <span class="at">lty =</span> <span class="st">"dashed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-trees" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-trees-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-trees-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-trees-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.1: CWD basal area in function of tree density, with linear regression line (solid line) and loess scatterplot smoother (dashed line).
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<p>We denote with <span class="math inline">\(E(Y|X=x)\)</span> the mean outcome for the subgroup of the study population consisting of subjects for which the explanatory variable <span class="math inline">\(X\)</span> takes on the value <span class="math inline">\(x\)</span>. For example, for the CWD example above, <span class="math inline">\(E(Y|X=1200)\)</span> is the mean CWD basal area per km of shoreline for lakes that have 1,200 trees per km along their shoreline. We could in principle calculate this mean by registering, for all lakes in the study population with 1,200 trees per km of shoreline, the CWD basal area and then taking the mean of these values. The mean <span class="math inline">\(E(Y|X=x)\)</span> is called a <em>conditional mean</em> because it describes a mean outcome, conditional on the fact that <span class="math inline">\(X=x\)</span>.</p>
<p>Now suppose that the mean outcome can be described linearly in function of the explanatory variable <span class="math inline">\(X\)</span>, which means that <span id="eq-linreg"><span class="math display">\[
    E(Y|X=x)=\alpha + \beta x,
\tag{2.1}\]</span></span> where <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are unknown numbers. In this expression, <span class="math inline">\(E(Y|X=x)\)</span> represents the value on the <span class="math inline">\(Y\)</span>-axis, <span class="math inline">\(x\)</span> the value on the <span class="math inline">\(X\)</span>-axis, the <em>intercept</em> <span class="math inline">\(\alpha\)</span> indicates the intersection with the <span class="math inline">\(Y\)</span>-axis, and <span class="math inline">\(\beta\)</span> is the <em>slope</em> of the line. This expression is called a <em>statistical model</em>. This naming suggests that certain assumptions will be placed on the distribution of the observations. In particular it assumes that the mean outcome varies linearly in function of the predictor <span class="math inline">\(X\)</span>. For this reason, this is also called a <em>simple linear regression model</em>. According to this model, every measurement <span class="math inline">\(Y\)</span> can be described, modulo an error term <span class="math inline">\(\epsilon\)</span>, as a linear function of the explanatory variable <span class="math inline">\(X\)</span>: <span class="math display">\[
    Y=E(Y|X=x)+\epsilon=\alpha+\beta x+\epsilon,
\]</span> where <span class="math inline">\(\epsilon\)</span> represents the deviation between the observed outcome and its (conditional) mean value, i.e., the uncertainty in the response variable.</p>
<p>The parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are unknowns. If we could observe the entire study population, we could determine both parameters exactly (by calculating for two <span class="math inline">\(x\)</span>-values the mean outcome and then solve the resulting system of linear equations as given by <a href="#eq-linreg" class="quarto-xref">Equation&nbsp;<span>2.1</span></a>). In reality we only observe a limited sample from the study population and hence we need to estimate both parameters based on the available information. The parameters are estimated by searching for the line that “best fits” the data.</p>
<p>In order to obtain a best-fitting line, we want that for each subject <span class="math inline">\(i\)</span>, the difference between the corresponding point on the regression line, <span class="math inline">\((x_i, \alpha + \beta x_i)\)</span>, and the observation itself, <span class="math inline">\((x_i, y_i)\)</span>, is as small as possible. This can be realised by choosing values for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> that minimise the sum of the squared distances between the predicted and the observed points: <span class="math display">\[
    \sum_{i=1}^n (y_i-\alpha-\beta x_i)^2.
\]</span> The obtained line is called the <em>least squares (regression) line</em>. The corresponding values or estimations <span class="math inline">\(\hat{\alpha}\)</span> for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\hat{\beta}\)</span> for <span class="math inline">\(\beta\)</span> are called the <em>least squares estimates</em>. It can be shown that <span class="math display">\[
    \hat{\beta}=\frac{\mbox{Cor}(x,y)s_y}{s_x}
\]</span> and that<br>
<span class="math display">\[
    \hat{\alpha}=\bar y - \hat{\beta} \bar x.
\]</span> Note that the slope of the least squares line is proportional to the correlation between the outcome and the explanatory variable.</p>
<p>Given the estimates <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span>, the linear regression model <a href="#eq-linreg" class="quarto-xref"><span>2.1</span></a> allows us to do two things:</p>
<ol type="1">
<li>To predict the expected outcome for subjects with a given <span class="math inline">\(x\)</span>-value for the explanatory variable. If these subjects have the predictor equal to <span class="math inline">\(X = x\)</span>, then the expected outcome, <span class="math inline">\(Y\)</span>, is on average <span class="math display">\[
E(Y \mid X = x) = \hat{\alpha}+\hat{\beta}x.
\]</span></li>
<li>To verify how much the outcome differs on average between two groups of subjects with a difference of <span class="math inline">\(\delta\)</span> units in the explanatory variable. This is: <span class="math display">\[
E(Y \mid X=x+\delta)-E(Y \mid X=x) = \alpha + \beta (x+\delta) -\alpha-\beta x = \beta\delta.
\]</span> In particular, <span class="math inline">\(\beta\)</span> can be interpreted as the difference in mean outcome between two subjects that differ by one unit in <span class="math inline">\(X\)</span>-value. This difference can be estimated by <span class="math inline">\(\hat{\beta}\)</span>.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Woody debris and tree density, continued
</div>
</div>
<div class="callout-body-container callout-body">
<p>We can build a linear model in R by means of the <code>lm</code> command:</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>m_cwd <span class="ot">&lt;-</span> <span class="fu">lm</span>(CWD.BASA <span class="sc">~</span> RIP.DENS, <span class="at">data =</span> trees)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_cwd)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = CWD.BASA ~ RIP.DENS, data = trees)

Residuals:
   Min     1Q Median     3Q    Max 
-38.62 -22.41 -13.33  26.16  61.35 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -77.09908   30.60801  -2.519 0.024552 *  
RIP.DENS      0.11552    0.02343   4.930 0.000222 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 36.32 on 14 degrees of freedom
Multiple R-squared:  0.6345,    Adjusted R-squared:  0.6084 
F-statistic:  24.3 on 1 and 14 DF,  p-value: 0.0002216</code></pre>
</div>
</div>
<p>The software reports <span class="math inline">\(\hat{\alpha}=-77.09908\)</span> and <span class="math inline">\(\hat{\beta}=0.11552\)</span>. We conclude that, per km of shoreline, the CWD basal area increases on average with 1.2 m<span class="math inline">\(^2\)</span> per increase of 10 trees in tree density. Furthermore, we can predict what CWD basal area can be expected for any given number of trees per km of shoreline. For example, if the tree density is 1,600 trees per km shoreline, we expect a mean CWD basal area of <span class="math inline">\(-77.09908 +0.11552\times 1600=108\)</span> m<span class="math inline">\(^2\)</span> per km shoreline.</p>
<p>From <a href="#fig-trees" class="quarto-xref">Figure&nbsp;<span>2.1</span></a> you can see that the dataset does not contain any lakes with a tree density of approximately 1,600 trees per km of shoreline. Based on the dataset it would thus not be possible, without using a statistical model, to obtain an estimate for the mean CWD basal area for that given tree density. However, assuming that the mean CWD basal area varies linearly with the riparian tree density, we can use all observations to estimate this mean. Hence we obtain a meaningful and precise result, if the condition of linearity is met of course.</p>
</div>
</div>
<p>For the results obtained from the linear regression model to be valid, it is important to verify that all conditions that are imposed by the model are met. So far, the only assumption we made was that the mean outcome varies linearly in function of the explanatory variable (later on, we will add more conditions to also determine the variability of the data around the regression line). This assumption can easily be verified graphically using a scatterplot where we plot the outcome in function of the explanatory variable and then check if the relation seems to follow a linear pattern. Deviations from linearity can usually be discovered more easily by means of a <em>residual plot</em>. This is a scatterplot with the explanatory variable on the <span class="math inline">\(X\)</span>-axis and the <em>residuals</em> on the <span class="math inline">\(Y\)</span>-axis. The residuals are the prediction errors that can be calculated as <span class="math display">\[
e_i=y_i-\hat{y}_i=y_i-\hat{\alpha}-\hat{\beta}x_i.
\]</span> They represent the vertical distance between the observation for subject <span class="math inline">\(i\)</span> and its prediction on the regression line.</p>
<p>In practice, it is often more convenient to put the fitted values on the <span class="math inline">\(x\)</span>-axis, rather than the values of the predictor. This is especially useful for multiple linear regression, where there are several predictors. We will follow this convention for the residual plot from now on.</p>
<p>If the assumption of linearity holds, then there should be no pattern visible in the residual plot. This is the case in <a href="#fig-residuals" class="quarto-xref">Figure&nbsp;<span>2.2</span></a> that shows a residual plot for the regression analysis of the CWD example. However, when the residuals reveal a nonlinear pattern, this means that extra terms should be added to the model to correctly predict the mean outcome. For example, if the residuals show a quadratic pattern, then we could write that approximately <span class="math inline">\(e_i\approx \delta_0+\delta_1 x_i+\delta_2 x_i^2\)</span> for some numbers <span class="math inline">\(\delta_0\)</span>, <span class="math inline">\(\delta_1\)</span>, and <span class="math inline">\(\delta_2\)</span>, and hence that the outcome <span class="math inline">\(y_i=\hat{\alpha}+\hat{\beta}x_i+e_i\approx (\hat{\alpha}+\delta_0)+(\hat{\beta}+\delta_1)x_i+\delta_2 x_i^2\)</span> (modulo an error term) is a quadratic function of <span class="math inline">\(x_i\)</span>. In that case it is best to switch to a quadratic regression model.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m_cwd, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-residuals" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-residuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-residuals-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-residuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.2: Residual plot for the CWD data.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Since the linearity of the model can only be verified over the observed range of the explanatory variable (for example, over the interval [771; 2,150] for the CWD data), it is important to understand that the results of a linear model cannot just be extrapolated past the largest or smallest observed <span class="math inline">\(X\)</span>-value. In the CWD example we can estimate that the mean CWD basal area for lakes with a riparian tree density of 750 per km of shoreline will be <span class="math inline">\(-77.09908 +0.11552\times 750=9.5\)</span> m<span class="math inline">\(^2\)</span>, but the observed data do not allow us verify the reliability of this estimation. After all, it could be that the regression line for low values of the predictor variable increases or decreases, causing the linear extrapolation to be misleading. Note that, for example, the prediction for a tree density of 500 per km of shoreline is very misleading, since it gives a negative result (<span class="math inline">\(-77.09908 +0.11552\times 500=-19\)</span> m<span class="math inline">\(^2\)</span>).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Frequency of Lap94 and distance from Southport
</div>
</div>
<div class="callout-body-container callout-body">
<p>For the next example, we consider the blue or common mussel (<em>Mytilus edulis</em>). We are especially interested in the frequency of the allele Lap94 with respect to the eastern distance from Southport, Connecticut, U.S.A.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/01-regression/Miesmuscheln-2.jpg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:25.0%"></p>
<figcaption>Mytilus edulis, the common mussel. Figure courtesy of <a href="https://en.wikipedia.org/wiki/File:Miesmuscheln-2.jpg">Wikipedia</a>, <a href="https://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA 3.0</a>.</figcaption>
</figure>
</div>
<p>We have obtained a dataset of 17 mussels, where for each mussel we record the frequency of the Lap94 allele, and the distance to the Southport seabord. This dataset is shown in <a href="#fig-southport" class="quarto-xref">Figure&nbsp;<span>2.3</span></a>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>southport <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"datasets/01-regression/southport.txt"</span>, <span class="at">sep =</span> <span class="st">" "</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(freq <span class="sc">~</span> km, <span class="at">data =</span> southport,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Distance (in km)"</span>,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Frequency"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># linear model</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>m_linear <span class="ot">&lt;-</span> <span class="fu">lm</span>(freq <span class="sc">~</span> km, <span class="at">data =</span> southport)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m_linear, <span class="at">lty =</span> <span class="st">"dotted"</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co"># quadratic model</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>m_quad <span class="ot">&lt;-</span> <span class="fu">lm</span>(freq <span class="sc">~</span> km <span class="sc">+</span> <span class="fu">I</span>(km<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> southport)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>km_dense <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">110</span>, <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(km_dense, <span class="fu">predict</span>(m_quad, <span class="at">new =</span> <span class="fu">data.frame</span>(<span class="at">km =</span> km_dense)))</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="co"># loess model</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>m_loess <span class="ot">&lt;-</span> <span class="fu">loess</span>(freq <span class="sc">~</span> km, <span class="at">data =</span> southport)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(southport<span class="sc">$</span>km, m_loess<span class="sc">$</span>fitted, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-southport" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-southport-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-southport-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-southport-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.3: Frequency of Lap94 in function of the eastern distance from Southport, with linear regression line (dotted line), quadratic regression line (solid line), and loess scatterplot smoother (dashed line)
</figcaption>
</figure>
</div>
</div>
</div>
<p>A linear regression model shows that the expected gene frequency differs by 2.2% between mussels that are located at a 10 km eastern distance from each other.</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>m_linear <span class="ot">&lt;-</span> <span class="fu">lm</span>(freq <span class="sc">~</span> km, <span class="at">data =</span> southport)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = freq ~ km, data = southport)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.13744 -0.05784  0.01486  0.03923  0.10675 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 0.045830   0.036361    1.26    0.227    
km          0.004514   0.000536    8.42 4.56e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.06955 on 15 degrees of freedom
Multiple R-squared:  0.8254,    Adjusted R-squared:  0.8137 
F-statistic:  70.9 on 1 and 15 DF,  p-value: 4.557e-07</code></pre>
</div>
</div>
<p><a href="#fig-southport-residuals" class="quarto-xref">Figure&nbsp;<span>2.4</span></a> shows a residual plot based on linear regression. We see that that residuals display a systematic pattern, which is approximately parabolic. This suggests that adding a quadratic term to the model will improve the reliability of the regression model.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m_linear, <span class="at">which =</span> <span class="dv">1</span>, <span class="at">main =</span> <span class="st">"Linear regression"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m_quad, <span class="at">which =</span> <span class="dv">1</span>, <span class="at">main =</span> <span class="st">"Quadratic regression"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-southport-residuals" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-southport-residuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-southport-residuals-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-southport-residuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.4: Residual plots for linear regression (left) and quadratic regression (right), with loess scatterplot smoother.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Adding a quadratic term gives the following model:</p>
<div class="cell">
<details open="" class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>m_quad <span class="ot">&lt;-</span> <span class="fu">lm</span>(freq <span class="sc">~</span> km <span class="sc">+</span> <span class="fu">I</span>(km<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> southport)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_quad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = freq ~ km + I(km^2), data = southport)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.10054 -0.03766 -0.01147  0.03678  0.11003 

Coefficients:
             Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept) 1.173e-01  4.805e-02   2.441   0.0285 *
km          5.257e-04  2.008e-03   0.262   0.7973  
I(km^2)     3.655e-05  1.786e-05   2.047   0.0599 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.06316 on 14 degrees of freedom
Multiple R-squared:  0.8656,    Adjusted R-squared:  0.8464 
F-statistic: 45.09 on 2 and 14 DF,  p-value: 7.919e-07</code></pre>
</div>
</div>
<p><a href="#fig-southport-residuals" class="quarto-xref">Figure&nbsp;<span>2.4</span></a> (right) shows a residual plot based on this quadratic regression and indicates that the previously found pattern has mostly disappeared. Hence this model better describes the data. In subsequent sections we will investigate whether the model can be improved further.</p>
</div>
</div>
</section>
<section id="the-residual-standard-deviation" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="the-residual-standard-deviation"><span class="header-section-number">2.2</span> The residual standard deviation</h2>
<p>The CWD linear regression model from the previous section indicates how much (in particular, what basal area of) woody debris we can expect along North American lakes with a certain tree density. However, it does not inform us how much this area can vary between lakes with the same tree density. Nevertheless, it is of the utmost importance to know this when we want to make predictions based on the regression model, since outcomes that vary a lot around the regression line can of course not be predicted accurately by using the regression line, as opposed to outcomes with little variation around the line which can be predicted relatively accurately.</p>
<p>If the outcomes for lakes with the same predictor value <span class="math inline">\(x\)</span> (i.e., tree density) are normally distributed, then it makes sense to express the variation of the outcomes around their mean by means of a <em>conditional variance</em> <span class="math inline">\(\text{Var}(Y \mid X=x)\)</span>. Similarly to the conditional mean <span class="math inline">\(E(Y \mid X=x)\)</span>, this indicates the variance on the outcomes for the subgroup from the study population consisting of lakes for which the tree density <span class="math inline">\(X\)</span> takes on the value <span class="math inline">\(x\)</span>. For example, <span class="math inline">\(\text{Var}(Y \mid X=1,300)\)</span> in the CWD example is the variance on the CWD basal area per km of shoreline for lakes with a riparian tree density of 1,300 per km. These variances cannot just be estimated, since there is only 1 observation in the dataset with a tree density of 1,300. When we examine <a href="#fig-residuals" class="quarto-xref">Figure&nbsp;<span>2.2</span></a>, we see that the points are equally spread around the regression line, irrespective of the tree density, and that the variability on the basal area of coarse woody debris does not seem to depend on the tree density. In this case, we call the outcomes <em>homoscedastic</em> or the variance is said to be <em>homogeneous</em>. It then makes sense to assume that the conditional variance <span class="math inline">\(\text{Var}(Y \mid X=x)\)</span> is constant: <span id="eq-homosc"><span class="math display">\[
    \text{Var}(Y \mid X=x) = \sigma^2.
\tag{2.2}\]</span></span> The constant <span class="math inline">\(\sigma\)</span> is called the <em>residual standard deviation</em>. If we assume <a href="#eq-homosc" class="quarto-xref">Equation&nbsp;<span>2.2</span></a>, we are able to determine the conditional variance <span class="math inline">\(\text{Var}(Y \mid X=1300)=\sigma^2\)</span>, because then it can be estimated based on the data for all lakes, as will be illustrated in the next paragraph.</p>
<p>As we have learned in descriptive statistics, the variation of the outcomes around their conditional mean can be described by means of the differences between the observations <span class="math inline">\(y_i\)</span> and their (estimated) mean <span class="math inline">\(\hat{\alpha}+\hat{\beta}x_i\)</span>, or in other words, through the residuals. However, the mean of the residuals is always 0 because the positive and negative deviations cancel each other out. Hence the mean residual is not a good measure for the variation, and it is more sensible to use the squared deviations <span class="math inline">\(e_i^2\)</span>. The mean of these <em>squared residuals</em> therefore will give a good measure. In particular it can be shown that the so-called <em>residual mean squared error</em>, given by <span id="eq-mse"><span class="math display">\[
    \hat{\sigma}^2=\frac{\sum_{i=1}^n e_i^2}{n-2}=s_y^2\{1-\mbox{Cor}(x,y)^2\}
\tag{2.3}\]</span></span> is a good (i.e., unbiased) estimate of <span class="math inline">\(\sigma^2\)</span>. Remark that the size of the residual mean squared error is closely connected with the correlation. If the outcome is independent from the predictor variable, the variability of the outcomes around the regression line is the same as the total variability, as denoted by the standard deviation <span class="math inline">\(s_y\)</span>. If the variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are (perfectly) linearly dependent on each other, the correlation is 1, and hence there is no variation around the regression line. This is logical, since in that case the data points form a straight line and therefore do not vary around that line.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Woody debris and tree density, continued
</div>
</div>
<div class="callout-body-container callout-body">
<p>Previously, the R model summary for the CWD model gave the following estimate for the residual standard deviation:</p>
<pre><code>Residual standard error: 36.32 on 14 degrees of freedom</code></pre>
<p>Assuming the CWD basal area is normally distributed for a given tree density, we can conclude that respectively 68% and 95% of those basal areas given a tree density of 1,300 per km can be expected to fall in the intervals <span class="math inline">\([73-36, 73+36] = [37, 109]\)</span> and <span class="math inline">\([73-2\times 36, 73 + 2\times 36] = [1, 145]\)</span>. Thus we obtain a fairly wide 95% reference interval for the CWD basal area when the tree density is 1,300 trees per km of shoreline. These intervals are not completely accurate since they do not take the imprecision of the estimates of the mean outcome and residual standard deviation into account. in the literature there exist so-called <em>prediction intervals</em> which do take this imprecision into account.</p>
</div>
</div>
<p>For the previous results to be valid, it is of course again important that all conditions imposed by the model are met. This time we do not only have the assumption of linearity, but more importantly also the assumption of homoscedasticity of the outcomes. Since, according to <a href="#eq-mse" class="quarto-xref">Equation&nbsp;<span>2.3</span></a>, the squared residuals are indicative for the variability that is present in the data, we can investigate this assumption by making a scatterplot of the squared residuals (on the <span class="math inline">\(Y\)</span>-axis) in function of the explanatory variable (on the <span class="math inline">\(X\)</span>-axis).This is illustrated for the CWD data in <a href="#fig-cwd-diagnostics" class="quarto-xref">Figure&nbsp;<span>2.5</span></a> (left), which seems to suggest that the variability increases for increasing tree densities. Consequently, the reference intervals that have been calculated assuming homoscedasticity cannot be fully trusted. In particular they might be too narrow for high tree densities and too wide for low tree densities.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m_cwd, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m_cwd, <span class="at">which =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-cwd-diagnostics" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cwd-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-cwd-diagnostics-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cwd-diagnostics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.5: Analysis of the CWD data. Left: scatterplot of the squared residuals. Right: QQ-plot of the residuals.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Even if the variance would be homogeneous, it is still important to verify that the outcomes are normally distributed for subjects with the same predictor value in order for the residual standard deviation to be a meaningful measure to describe the variability on the data and for the calculated reference intervals to be correct. A QQ-plot of the outcomes would be misleading, since this checks the normality of all measurements as a whole, not the normality of the measurements for subjects with the same predictor value. It can be shown that normally distributed outcomes for a given <span class="math inline">\(x\)</span>-value implies that the residuals are also approximately normally distributed. Hence deviations from normality in a QQ-plot for the residuals indicate that the outcomes are not normally distributed for a fixed <span class="math inline">\(x\)</span>. <a href="#fig-cwd-diagnostics" class="quarto-xref">Figure&nbsp;<span>2.5</span></a> (right) illustrates this for the CWD data and shows deviations from normality. This is not surprising, since heterogeneity of the variance often goes together with non-normality, in particular skewness, of the data.</p>
<p>Finally it is also necessary that all outcomes are independent to obtain correct estimations of the residual standard deviation. This would not be the case in so-called longitudinal studies where the outcome is measured repeatedly over time for the same subject.</p>
<p>In the next section we will describe how to handle deviations from the previously mentioned assumptions.</p>
</section>
<section id="deviations-from-the-assumptions-in-linear-regression-analysis" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="deviations-from-the-assumptions-in-linear-regression-analysis"><span class="header-section-number">2.3</span> Deviations from the assumptions in linear regression analysis</h2>
<p>The primary assumption in linear regression analysis is the assumption that the outcome varies linearly in the predictor. Whenever residual plots suggest that this is not the case, we could consider transforming the explanatory variable. In dose-response studies where, for example, the impact of increasing doses of a toxic substance on a phenotype in test animals is studied, the (mean) outcome will often not vary linearly in function of the administered dose, but will vary linearly in function of the logarithm of the administered dose. In that case, we could opt to include the log-transformed explanatory variable as a predictor in the model. For other examples it might happen that other transformations than the log-transformation are better suited, such as the square root (<span class="math inline">\(\sqrt{x}\)</span>) or the inverse (<span class="math inline">\(1/x\)</span>) transformation.</p>
<p>An advantage of transforming the explanatory variable is that it is easy to accomplish, a disadvantage is that this often complicates the interpretation of the coefficient in the model. However, this will not happen when applying a log-transformation, because an increase in log-dose with, for example, 1 unit is equivalent with a change in dose with a factor <span class="math inline">\(\exp(1)=2.78\)</span>. Transforming the explanatory variable does not have a direct influence on the homogeneity of the variance or on the normality of the outcomes (for fixed values of the predictor variable), except by improving the linearity of the model. Therefore this option is often less suitable when there are strong deviations from normality.</p>
<p>An alternative option to improve the linearity of the model, is <em>higher-order regression</em>. Here nonlinear relations are directly modeled by including higher-order terms in the model. We could, for example, consider a second-order model <span class="math display">\[
    E(Y|X) = \alpha+\beta_1X+\beta_2X^2,
\]</span> in which case the regression curve will be parabolic, or a third-order model: <span class="math display">\[
    E(Y|X) = \alpha+\beta_1X+\beta_2X^2+\beta_3X^3,
\]</span> where the regression curve will be a polynomial of degree 3. This method can be seen as some sort of transformation of the explanatory variable and essentially has the same properties, advantages, and disadvantages. However, an additional advantage is that in this case there is no need to decide yourself on a transformation, because the method itself will implicitly estimate a good polynomial.</p>
<p>Finally we could also consider transforming the outcome instead of the explanatory variable. For example, when the outcomes are right skewed, it is often appropriate to perform a log-transformation of the outcomes and include this new variable as the outcome variable in the model. Usually this not only improves the linearity of the model, but it will also improve the normality of the residuals with a more constant variability. This method has the same advantages and disadvantages as a transformation of the explanatory variable. A big difference between both options that greatly influences the choice between both methods is that, contrary to transformations of the outcome, transformations of the independent variable have little to no influence on the distribution of the residuals (unless via changes in their mean). Normally distributed residuals in particular will remain rather normally distributed after transforming the explanatory variable, whereas they might no longer be normally distributed after a transformation of the outcome variable, and vice versa.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Woody debris and tree density, continued
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the analysis of the CWD model we determined that, although the linearity assumption is well met for the chosen model, the residuals are not normally distributed with a constant variance. Therefore a transformation of the outcome is the only sensible choice out of the previously mentioned options. The fact that the outcomes can only take on nonnegative values compels us to consider the log-transformation because that transformation extends the range of the outcomes to all real values. This is indeed desirable since a linear regression model basically allows the mean outcome to vary from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(+\infty\)</span>, as long as we vary the predictor <span class="math inline">\(x\)</span> enough. Remark that we, as a result of this, indeed obtained negative predictions for the CWD basal area for lakes with relatively few trees along the shoreline.</p>
<p>Log-transforming the outcome gives us the following model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>m_log <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(CWD.BASA) <span class="sc">~</span> RIP.DENS, <span class="at">data =</span> trees)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_log)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log(CWD.BASA) ~ RIP.DENS, data = trees)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.23086 -0.78379  0.04559  0.72335  2.05022 

Coefficients:
              Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept) -0.5570100  1.0739690  -0.519   0.6121   
RIP.DENS     0.0031573  0.0008222   3.840   0.0018 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.274 on 14 degrees of freedom
Multiple R-squared:  0.513, Adjusted R-squared:  0.4782 
F-statistic: 14.75 on 1 and 14 DF,  p-value: 0.001802</code></pre>
</div>
</div>
<p>The residual plots for this model are shown in <a href="#fig-log-cwd-residuals" class="quarto-xref">Figure&nbsp;<span>2.6</span></a> below.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>add_loess_line <span class="ot">&lt;-</span> <span class="cf">function</span>(x, y) {</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    ll <span class="ot">&lt;-</span> <span class="fu">loess</span>(y <span class="sc">~</span> x)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    j <span class="ot">&lt;-</span> <span class="fu">order</span>(x)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lines</span>(x[j], ll<span class="sc">$</span>fitted[j], <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(trees<span class="sc">$</span>RIP.DENS, m_log<span class="sc">$</span>residuals,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Riparian tree density"</span>,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Residuals"</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="fu">add_loess_line</span>(trees<span class="sc">$</span>RIP.DENS, m_log<span class="sc">$</span>residuals)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(trees<span class="sc">$</span>RIP.DENS, m_log<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Riparian tree density"</span>,</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Squared residuals"</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="fu">add_loess_line</span>(trees<span class="sc">$</span>RIP.DENS, m_log<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m_log, <span class="at">which =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-log-cwd-residuals" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-log-cwd-residuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-log-cwd-residuals-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-log-cwd-residuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.6: Analysis of the CWD data (linear trend on logarithmic scale). Left: scatterplot of the residuals. Middle: scatterplot of the squared residuals. Right: QQ-plot of the residuals.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Although the residuals follow relatively well the normal distribution, deviations from linearity and homoscedasticity emerge. The pattern in <a href="#fig-log-cwd-residuals" class="quarto-xref">Figure&nbsp;<span>2.6</span></a> seems to be parabolic and makes it necessary to include a second order term in the model, so that we obtain the following model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>m_log_quad <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(CWD.BASA) <span class="sc">~</span> RIP.DENS <span class="sc">+</span> <span class="fu">I</span>(RIP.DENS<span class="sc">^</span><span class="dv">2</span>),</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> trees)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_log_quad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log(CWD.BASA) ~ RIP.DENS + I(RIP.DENS^2), data = trees)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.6872 -0.4462 -0.1621  0.4214  2.1399 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)   -9.686e+00  3.114e+00  -3.110  0.00828 **
RIP.DENS       1.726e-02  4.673e-03   3.693  0.00270 **
I(RIP.DENS^2) -4.960e-06  1.628e-06  -3.047  0.00935 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.01 on 13 degrees of freedom
Multiple R-squared:  0.7159,    Adjusted R-squared:  0.6722 
F-statistic: 16.38 on 2 and 13 DF,  p-value: 0.0002801</code></pre>
</div>
</div>
<p>Compared to <a href="#fig-log-cwd-residuals" class="quarto-xref">Figure&nbsp;<span>2.6</span></a>, the residual plots for this model show somewhat less of a pattern.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(trees<span class="sc">$</span>RIP.DENS, m_log_quad<span class="sc">$</span>residuals,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Riparian tree density"</span>,</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Residuals"</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="fu">add_loess_line</span>(trees<span class="sc">$</span>RIP.DENS, m_log_quad<span class="sc">$</span>residuals)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(trees<span class="sc">$</span>RIP.DENS, m_log_quad<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Riparian tree density"</span>,</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Squared residuals"</span>)</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="fu">add_loess_line</span>(trees<span class="sc">$</span>RIP.DENS, m_log_quad<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m_log_quad, <span class="at">which =</span> <span class="dv">2</span>)      </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-log-quad-cwd-residuals" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-log-quad-cwd-residuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-log-quad-cwd-residuals-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-log-quad-cwd-residuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.7: Analysis of the CWD data (quadratic trend on logarithmic scale). Left: scatterplot of the residuals. Middle: scatterplot of the squared residuals. Right: QQ-plot of the residuals.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>m_log_quad <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="fu">log</span>(CWD.BASA) <span class="sc">~</span> RIP.DENS <span class="sc">+</span> <span class="fu">I</span>(RIP.DENS<span class="sc">^</span><span class="dv">2</span>), <span class="at">data =</span> trees)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_log_quad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log(CWD.BASA) ~ RIP.DENS + I(RIP.DENS^2), data = trees)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.6872 -0.4462 -0.1621  0.4214  2.1399 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)   -9.686e+00  3.114e+00  -3.110  0.00828 **
RIP.DENS       1.726e-02  4.673e-03   3.693  0.00270 **
I(RIP.DENS^2) -4.960e-06  1.628e-06  -3.047  0.00935 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.01 on 13 degrees of freedom
Multiple R-squared:  0.7159,    Adjusted R-squared:  0.6722 
F-statistic: 16.38 on 2 and 13 DF,  p-value: 0.0002801</code></pre>
</div>
</div>
<p>We conclude that <span class="math display">\[
    E\{\ln(Y)|X\}=-9.7+0.017X-5.0 \ 10^{-6}X^2
\]</span> or, equivalently, that the geometric mean CWD basal area varies in function of the tree density <span class="math inline">\(X\)</span> as <span class="math inline">\(\exp(-9.7+0.017X-5.0 \ 10^{-6}X^2)\)</span>. Although the estimated geometric mean for high tree densities suggests a stabilising or even declining trend in the amount of CWD with increasing tree density, the accompanying 95% confidence intervals indicate that this suggestion is very imprecise and that even strong increases are compatible with the observed data. The regression line and associated confidence intervals are shown in <a href="#fig-reg-line-m-log-quad" class="quarto-xref">Figure&nbsp;<span>2.8</span></a> below.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>dense_like <span class="ot">&lt;-</span> <span class="cf">function</span>(s, <span class="at">n =</span> <span class="dv">100</span>) {</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq</span>(<span class="fu">min</span>(s), <span class="fu">max</span>(s), <span class="at">length.out =</span> n)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(trees<span class="sc">$</span>RIP.DENS, trees<span class="sc">$</span>CWD.BASA,</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Riparian tree density"</span>,</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"CWD basal area"</span>,</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">600</span>))</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(m_cwd, <span class="at">lty =</span> <span class="st">"dotted"</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>x_dense <span class="ot">&lt;-</span> <span class="fu">dense_like</span>(trees<span class="sc">$</span>RIP.DENS)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">predict</span>(m_log_quad, <span class="at">new =</span> <span class="fu">data.frame</span>(<span class="at">RIP.DENS =</span> x_dense), <span class="at">interval =</span> <span class="st">"confidence"</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">exp</span>(p)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x_dense, p[,<span class="st">"fit"</span>], <span class="at">lty =</span> <span class="st">"solid"</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x_dense, p[,<span class="st">"lwr"</span>], <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x_dense, p[,<span class="st">"upr"</span>], <span class="at">lty =</span> <span class="st">"dashed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-reg-line-m-log-quad" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-reg-line-m-log-quad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-reg-line-m-log-quad-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-reg-line-m-log-quad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.8: Scatterplot of the CWD basal area versus tree density <span class="math inline">\(X\)</span> with linear regression line (dotted line), estimated geometric mean <span class="math inline">\(\exp(-9.7+0.017X-5.0 \ 10^{-6}X^2)\)</span> (solid line), and accompanying 95% confidence intervals (dashed lines).
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<p>For certain types of outcomes there exist <em>variance stabilising transformations</em> for the outcome that are aimed at fulfilling the assumption of homoscedasticity. For proportions or percentages we often use the arcsin-transformation which transforms the outcome <span class="math inline">\(Y\)</span> in <span class="math inline">\(\arcsin\sqrt{Y}\)</span>, because it can be shown that percentages (given certain conditions) have a constant variance after such a transformation. If the transformation of the outcome is not helping or is not appropriate (e.g., because it is harmful for the interpretation of the model) and there is a consistent pattern of unequal variance (e.g., increasing variance in the outcome for increasing predictor values), we could also determine <em>weighted least squares</em> estimates. Another alternative would be to estimate <em>generalized linear models</em>, which also allow other distributions than the normal one. Both types of solutions, i.e., weighted least squares estimates and generalized linear models, are beyond the scope of this course.</p>
</section>
<section id="inference-in-regression-models" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="inference-in-regression-models"><span class="header-section-number">2.4</span> Inference in regression models</h2>
<p>In linear regression analysis we often want to test whether or not the slope <span class="math inline">\(\beta\)</span> is equal to 0, i.e., whether or not a linear relation between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> exists. We wish, for example, to test if the CWD basal area per km is linearly related to the tree density, or if there exists a linear relation between the gene frequency of the allele Lap94 in the mussel Mytilus edulis and the eastern distance from Southport. We can show that the least squares estimate <span class="math inline">\(\hat{\beta}\)</span> is a sensible measure to perform tests on <span class="math inline">\(\beta\)</span> since it is an unbiased estimator of <span class="math inline">\(\beta\)</span> (and hence not systematically too high or too low), on the condition that the model is correct. If additionally the outcomes are normally distributed for a given predictor value <span class="math inline">\(X\)</span>, and have a homogeneous variance, then its standard error can be estimated as <span class="math display">\[
    SE(\hat{\beta})=\sqrt{\frac{MSE}{\sum_i (X_i-\bar X)^2}},
\]</span> where the (<span class="math inline">\(MSE\)</span>) is defined as <span class="math inline">\(\frac{1}{n}\sum_{i=1}^n (Y_i - \hat{Y}_i)^2\)</span>, and we can obtain tests and confidence intervals for <span class="math inline">\(\beta\)</span> based on <span class="math display">\[
    \frac{\hat{\beta}-\beta}{SE(\hat{\beta})}\sim t_{n-2}.
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Frequency of Lap94 and distance from Southport
</div>
</div>
<div class="callout-body-container callout-body">
<p>Previously we established, admittedly under the wrong assumption that the gene frequency varies linearly in function of the eastern distance from Southport, the following model:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = freq ~ km, data = southport)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.13744 -0.05784  0.01486  0.03923  0.10675 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 0.045830   0.036361    1.26    0.227    
km          0.004514   0.000536    8.42 4.56e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.06955 on 15 degrees of freedom
Multiple R-squared:  0.8254,    Adjusted R-squared:  0.8137 
F-statistic:  70.9 on 1 and 15 DF,  p-value: 4.557e-07</code></pre>
</div>
</div>
<p>Based on this output we can construct a 95% confidence interval for <span class="math inline">\(\beta\)</span> as <span class="math display">\[
    [0.004514 - 2.13\times 0.000536,0.004514 + 2.13\times 0.000536]=[0.003372,0.005656],
\]</span> where we use the fact that we posses <span class="math inline">\(n=17\)</span> observations and that <span class="math inline">\(t_{15,0.975}=2.13\)</span>. We conclude that the mean increase in the frequency of the allele Lap94 as we move 10 km east of Southport can be expected between 3.372% and 5.656% with 95% confidence. The p-value for the test of the null hypothesis <span class="math inline">\(\beta=0\)</span> (versus the alternative <span class="math inline">\(\beta\ne 0\)</span>) is the probability that a <span class="math inline">\(t_{15}\)</span>-distributed random variable in absolute value is larger than <span class="math inline">\(0.004515/0.000536 = 8.42\)</span>. This probability is <span class="math inline">\(4.56 \times 10^{-7}\)</span> and gives a very strong indication that there is a change in mean allele frequency in the eastern direction from Southport.</p>
</div>
</div>
<p>We could also test if the intercept takes on a certain value (e.g., 0). Again the least squares estimate <span class="math inline">\(\hat{\alpha}\)</span> is meaningful since it is an unbiased estimator of <span class="math inline">\(\alpha\)</span>, provided that the model is correct. If additionally the outcomes are normally distributed for a given predictor value <span class="math inline">\(X\)</span>, and have a homogeneous variance, then its standard error can be estimated as <span class="math display">\[
    SE(\hat{\alpha})=\sqrt{MSE\left\{\frac{1}{n}+\frac{\bar X^2}{\sum_i (X_i-\bar X)^2}\right\}}.
\]</span> Tests and confidence intervals for <span class="math inline">\(\alpha\)</span> can be obtained based on <span class="math display">\[
    \frac{\hat{\alpha}-\alpha}{SE(\hat{\alpha})}\sim t_{n-2}.
\]</span> Similarly, <span class="math inline">\(\hat{Y}_h=\hat{\alpha}+\hat{\beta}X_h\)</span> will be an unbiased estimator of <span class="math inline">\(E(Y|X_h)=\alpha+\beta X_h\)</span>. Its standard error is <span class="math display">\[
    SE(\hat{Y}_h)=\sqrt{MSE\left\{\frac{1}{n}+\frac{(X_h-\bar X)^2}{\sum_i (X_i-\bar X)^2}\right\}}.
\]</span> and tests and confidence intervals for <span class="math inline">\(E(Y|X_h)\)</span> depend on <span class="math display">\[
    \frac{\hat{Y}_h-E(Y|X_h)}{SE(\hat{Y}_h)}\sim t_{n-2}.
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Frequency of Lap94 and distance from Southport
</div>
</div>
<div class="callout-body-container callout-body">
<p>The p-value for the test that the allele frequency <span class="math inline">\(\alpha\)</span> in Southport is 1%, versus the alternative that it would be less, is the probability that a <span class="math inline">\(t_{15}\)</span>-distributed random variable is smaller than <span class="math inline">\((0.045830 - 0.01)/0.036361=0.9853964\)</span>. This probability is 0.17 and suggests that, at the 5% significance level, there is not enough evidence to support the claim that the allele frequency in Southport is less than 1%. A 95% confidence interval for <span class="math inline">\(\alpha\)</span> is obtained as <span class="math display">\[
    [0.045830 - 2.13\times 0.036361, 0.045830 + 2.13\times 0.036361]=[-0.031619,0.123279].
\]</span> The fact that this interval contains negative values suggests that the allele frequency <span class="math inline">\(\alpha\)</span> in Southport was estimated very inaccurately and that the linear model probably does not describe these data very well (since theoretically allele frequencies cannot be negative).</p>
</div>
</div>
</section>
<section id="the-multiple-correlation-coefficient" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="the-multiple-correlation-coefficient"><span class="header-section-number">2.5</span> The multiple correlation coefficient</h2>
<p>For the data in the CWD example, the standard deviation on the CWD basal area is 58.03 per km and the residual standard deviation is 36.32 per km. This shows that the measurements of the outcome vary less for lakes with the same tree density than in the entire population of lakes. This is not surprising, because part of the variability on the outcome measurements is explained by the fact that different lakes have different tree densities. In this section we will further exploit this idea to gain insight in the quality of the regression line.</p>
<p>The total squared deviation of the data around their mean can be split as follows: <span class="math display">\[\begin{eqnarray*}
SS_{Total}=\sum_{i=1}^n (y_i-\bar y)^2&amp;=&amp;\sum_{i=1}^n (\hat{\alpha}+\hat{\beta}x_i-\bar y)^2+ \sum_{i=1}^n (y_i-\hat{\alpha}-\hat{\beta}x_i)^2 \\
&amp;=&amp;\sum_{i=1}^n (\hat{\alpha}+\hat{\beta}x_i-\bar y)^2+ \sum_{i=1}^n e_i^2 \\
&amp;=&amp;SS_{Regression}+SS_{Residual} \,.
\end{eqnarray*}\]</span> For the second equality, we’ve used the defining relations for the coefficients of a linear regression, i.e. <span class="math display">\[
   \sum_{i=1}^n ( \hat{\alpha} + \hat{\beta} x_i - y_i) = 0 \quad \text{and} \quad \sum_{i=1}^n ( \hat{\alpha} + \hat{\beta} x_i - y_i) x_i = 0
\]</span> to show that the cross-product vanishes.</p>
<p>In this sum, <span class="math inline">\(SS_{Regression}=\sum_{i=1}^n (\hat{\alpha}+\hat{\beta}x_i-\bar y)^2\)</span> indicates how much the points on the regression line vary around the group mean <span class="math inline">\(\bar y\)</span>, and the <span class="math inline">\(SS_{Residual}=\sum_{i=1}^n e_i^2\)</span> reflects the residual variation of the observations around the regression line. The latter is called the <em>residual sum of squares</em> and indicates how much of the variation on the measurements is not explained by the regression model. The former is the <em>regression sum of squares</em> and indicates the amount of variability on the measurements that is explained by the regression model. The ratio of the regression sum of squares and the total sum of squares <span class="math inline">\(SS_{Total}\)</span>, <span class="math display">\[
    R^2=\frac{SS_{Regression}}{SS_{Total}}
\]</span> expresses the percentage of the variation on the data that is captured by their association with the explanatory variable, and is called the <em>coefficient of determination</em> or <em>multiple correlation coefficient</em>. It is generally denoted by <span class="math inline">\(R^2\)</span> and is a measure for the <em>predictive value</em> of the explanatory variable. In other words, it expresses how well the explanatory variable(s) predict(s) the outcome. This coefficient lies always between 0 and 1, where a value equal to 1 indicates that there is no residual variation around the regression line en hence the outcome shows a perfect (linear) relationship with the predictor. Analogously, a value 0 of <span class="math inline">\(R^2\)</span> implies that there is no association between the outcome and the predictor.</p>
<p>Often it is incorrectly claimed that a linear regression model is bad if the multiple correlation coefficient is low (e.g., 0.2). If the goal of the study is to predict the outcome based on the explanatory variables, a large value of <span class="math inline">\(R^2\)</span> is indeed needed because in the case of a low value there remains a lot of variability on the outcomes that is not explained by the explanatory variables. However, if the goal of the study is to determine the effect of an exposure on the outcome, then a linear regression model is good as soon as it correctly describes the association between on the one hand the outcome and on the other hand the exposure and possible confounders. Whenever exposure and confounders are weakly related to the outcome, then a small <span class="math inline">\(R^2\)</span>-value is expected, even if a correct regression model is used.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Woody debris and tree density
</div>
</div>
<div class="callout-body-container callout-body">
<p>Recall that we found the following model for the logarithm of the CWD basal area and the riparian tree density:</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_log_quad)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = log(CWD.BASA) ~ RIP.DENS + I(RIP.DENS^2), data = trees)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.6872 -0.4462 -0.1621  0.4214  2.1399 

Coefficients:
                Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)   -9.686e+00  3.114e+00  -3.110  0.00828 **
RIP.DENS       1.726e-02  4.673e-03   3.693  0.00270 **
I(RIP.DENS^2) -4.960e-06  1.628e-06  -3.047  0.00935 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.01 on 13 degrees of freedom
Multiple R-squared:  0.7159,    Adjusted R-squared:  0.6722 
F-statistic: 16.38 on 2 and 13 DF,  p-value: 0.0002801</code></pre>
</div>
</div>
<p>We conclude that 71.6% of the variability on the log-transformed CWD basal area is explained by its association with the tree density. The riparian tree density is thus strongly predictive for the CWD basal area.</p>
</div>
</div>
</section>
<section id="multiple-linear-regression" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="multiple-linear-regression"><span class="header-section-number">2.6</span> Multiple linear regression</h2>
<p>So far we focused on describing the association between a certain outcome <span class="math inline">\(Y\)</span> and a single predictor <span class="math inline">\(X\)</span>. However, it is often more useful to describe the mean outcome not in terms of only one, but in terms of multiple predictors at the same time. This is illustrated in the following examples:</p>
<ol type="1">
<li>Often the association between a predicting variable <span class="math inline">\(X\)</span> and an outcome <span class="math inline">\(Y\)</span> will be disturbed due to a confounder <span class="math inline">\(C\)</span>. For example, when determining the effect of asbestos (<span class="math inline">\(X\)</span>) on the respiratory function (<span class="math inline">\(Y\)</span>), age (<span class="math inline">\(C\)</span>) is a confounder because it influences both the duration of the exposure and the respiratory function. To correct for this confounding, it is necessary to describe the association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> separately for people of the same age (in other words, individuals with the same value for the confounder). Performing a separate linear regression for each observed age <span class="math inline">\(c\)</span> amongst those people of that age <span class="math inline">\(c\)</span>, doesn’t make sense since usually there are only very little people with exactly the same age in a study. Especially when there are multiple confounders, this becomes problematic. In this section we will solve this problem by including the confounder <span class="math inline">\(C\)</span> in the linear model.</li>
<li>In many studies we are interested in knowing which group of variables influences the outcome most. For example, understanding which aspects of habitat and human activity have a major impact on the biodiversity of the rain forest is an important objective of conservation biology. To that end, not only the size of the forest has to be taken into account, but also other factors, such as age and altitude of the forest, proximity of other forests, and so on. A study of the simultaneous effect of the different variables will allow us to get a deeper understanding of the variation in biodiversity between different forests. By inspecting in particular forests with a low or high biodiversity, new predictive factors for biodiversity might be discovered.</li>
<li>Whenever we want to predict an outcome for individuals, it is crucial that a lot of predictive information is available and that this information is used simultaneously in a regression model. For example, the prognosis after treatment is highly uncertain for patients with an advanced stage of breast cancer. However, based on measured predictors before and after the operation, it would be possible to construct regression models that allow to predict a prognosis for each patient, using his or her own characteristics. Related predictions (but then for mortality risk) are used daily in intensive care units to express the severity of a patient’s health. It goes without saying that better predictions can be made when a large number of predictors is taken into account at the same time.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mineral composition vs growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this example we study the relation between the growth and mineral composition of the needles of the Japanese larch. The height <span class="math inline">\(Y\)</span> of 26 trees was measured in cm, and for each tree the proportions of nitrogen <span class="math inline">\(X_n\)</span>, phosphorus <span class="math inline">\(X_f\)</span>, potassium <span class="math inline">\(X_p\)</span> and residual ash <span class="math inline">\(X_r\)</span> in dried needles were registered. Univariate regression models such as <span class="math display">\[
    E(Y|X_f)=\alpha+\beta_f X_f
\]</span> only allow us to predict the height of a tree based on a single mineral. Obviously, we could obtain more accurate predictions if multiple minerals are taken into account at the same time.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./images/01-regression/Larix-kaempferi.jpeg" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:30.0%"></p>
<figcaption>Japanese larch, or <em>Larix kaempferi</em>. Image courtesy of <a href="https://en.wikipedia.org/wiki/Larix_kaempferi#/media/File:Larix-kaempferi.JPG">Wikipedia</a>, <a href="https://creativecommons.org/licenses/by-sa/3.0/">CC BY-SA 3.0</a></figcaption>
</figure>
</div>
<p>Note that for example the coefficient <span class="math inline">\(\beta_f\)</span> in such a model might not show the pure effect of phosphorus. It is true that <span class="math inline">\(\beta_f\)</span> represents the mean difference in length between trees that differ by 1 unit in phosphorus, but even if phosphorus would not have an influence on the growth of the Japanese larch, it could still be possible that trees with a higher proportion of phosphorus are larger (and thus <span class="math inline">\(\beta_f&gt;0\)</span>) because, for example, they also contain more potassium. This is a problem of confounding (the effect of phosphorus is confounded with the effect of potassium) that can be resolved by comparing trees with a different level of phosphorus, but with an identical proportion of potassium. We will see in this section that multiple linear regression models make this possible in a natural way.</p>
</div>
</div>
<p>The technique that we will use to this end is called <em>multiple linear regression</em>, as opposed to simple linear regression used before. Suppose we observed a number of explanatory variables <span class="math inline">\(X_1,...,X_p\)</span> and an outcome <span class="math inline">\(Y\)</span> for <span class="math inline">\(n\)</span> subjects. Suppose furthermore that the mean outcome can be described linearly with respect to these variables, i.e., <span id="eq-mlinreg"><span class="math display">\[
    E(Y|X_1=x_1,...,X_p=x_p)=\alpha + \beta_1 x_1 + ... +\beta_p x_p,
\tag{2.4}\]</span></span> where <span class="math inline">\(\alpha,\beta_1,...,\beta_p\)</span> are unknown. The principle of the <em>least squares method</em>, which we applied before, can also be used on this model to obtain estimates of these unknown numbers. The formulas for these estimates are of course more complex than before, but we will rely on computer software to do the calculations for us. For any given estimates <span class="math inline">\(\hat{\alpha},\hat{\beta}_1,...,\hat{\beta}_p\)</span>, the linear regression model <a href="#eq-mlinreg" class="quarto-xref"><span>2.4</span></a> will allow us to</p>
<ol type="1">
<li>Predict the expected outcome for subjects with given values <span class="math inline">\(x_1,...,x_p\)</span> of the explanatory variables. This outcome is estimated as <span class="math inline">\(\hat{\alpha}+\hat{\beta}_1x_1+...+\hat{\beta}_px_p\)</span>.</li>
<li>Verify to what extent the mean outcome differs between 2 groups of subjects that differ <span class="math inline">\(\delta\)</span> units for one of the explanatory variables <span class="math inline">\(X_j, j=1,...,p\)</span>, but have the same values for all other variables <span class="math inline">\(\{X_k,k=1,...,p,k\ne j\}\)</span>. After all: <span class="math display">\[\begin{align*}
&amp; E(Y|X_1=x_1,...,X_j=x_j+\delta,...,X_p=x_p) -E(Y|X_1=x_1,...,X_j=x_j,...,X_p=x_p) \\
&amp; =\alpha + \beta_1 x_1 + ... + \beta_j(x_j+\delta)+...+\beta_p x_p -\alpha - \beta_1 x_1 - ... - \beta_jx_j-...-\beta_p x_p \\
&amp; = \beta_j\delta \,.
\end{align*}\]</span> In particular, we can interpret <span class="math inline">\(\beta_j\)</span> as the difference in mean outcome between subjects that differ 1 unit in the value of <span class="math inline">\(X_j\)</span>, but have the same value for all other explanatory variables in the model. This difference is estimated by <span class="math inline">\(\hat{\beta}_j\)</span>.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mineral composition vs growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>An analysis of the simple linear regression model <span class="math inline">\(E(Y|X_f)=\alpha+\beta_f X_f\)</span> in R gives the following output:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>needles <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"./datasets/01-regression/needles.txt"</span>, <span class="at">sep =</span> <span class="st">'</span><span class="sc">\t</span><span class="st">'</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>m_needles_simple <span class="ot">&lt;-</span> <span class="fu">lm</span>(length <span class="sc">~</span> phosphor, <span class="at">data =</span> needles)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_needles_simple)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = length ~ phosphor, data = needles)

Residuals:
     Min       1Q   Median       3Q      Max 
-103.398  -42.582    2.331   40.845  120.220 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)   -69.11      45.99  -1.503    0.146    
phosphor     1060.29     177.08   5.988 3.51e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 61.71 on 24 degrees of freedom
Multiple R-squared:  0.599, Adjusted R-squared:  0.5823 
F-statistic: 35.85 on 1 and 24 DF,  p-value: 3.511e-06</code></pre>
</div>
</div>
<p>Based on these data, we conclude that trees with a phosphorus level that is 0.1% higher, are on average 1.06m taller. An analysis of the multiple linear regression model <span class="math display">\[
    E(Y|X_n,X_f,X_p,X_r)=\alpha+\beta_n X_n+\beta_f X_f+\beta_p X_p+\beta_r X_r
\]</span> drastically changes this result, as indicated in the output:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>m_needles_multiple <span class="ot">&lt;-</span> <span class="fu">lm</span>(length <span class="sc">~</span> nitrogen <span class="sc">+</span> phosphor <span class="sc">+</span> potassium <span class="sc">+</span> residu, <span class="at">data =</span> needles)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_needles_multiple)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = length ~ nitrogen + phosphor + potassium + residu, 
    data = needles)

Residuals:
   Min     1Q Median     3Q    Max 
-61.56 -29.11  10.28  24.72  80.29 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -185.33      36.30  -5.106 4.67e-05 ***
nitrogen       97.76      24.57   3.979 0.000684 ***
phosphor      256.97     169.91   1.512 0.145321    
potassium     126.57      46.43   2.726 0.012653 *  
residu         40.28      36.61   1.100 0.283773    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 37.87 on 21 degrees of freedom
Multiple R-squared:  0.8679,    Adjusted R-squared:  0.8427 
F-statistic: 34.48 on 4 and 21 DF,  p-value: 5.967e-09</code></pre>
</div>
</div>
<p>The coefficient for phosphorus now implies that trees with an increase of 0.1% in their phosphorus level, but with the same levels of nitrogen, potassium, and residual ash, are only 25.7 cm taller. The reason why we find such a difference of more than 1 m, can be found in the fact that trees that differ 0.1% in phosphorus level, also often differ in their levels of nitrogen, potassium, and residual ash.</p>
<p>The <span class="math inline">\(R^2\)</span>-value in the output is 86.8%, which tells us that the majority of the variability on the length of Japanese larches can be explained by the mineral composition of the needles. The 4 chosen minerals are therefore strongly predictive for the outcome.</p>
</div>
</div>
<p>The previous example illustrates that multiple linear regression can be usefully applied to control for confounding. Assume, for example, that the association between variables <span class="math inline">\(X\)</span> (e.g., exposure to asbestos) and <span class="math inline">\(Y\)</span> (e.g., respiratory function) is perturbed by a third variable <span class="math inline">\(C\)</span> (e.g., age). We can then control for this by fitting the following multiple regression model: <span class="math display">\[
    E(Y|X,C)=\alpha+\beta_1X+\beta_2C.
\]</span> Assuming the linearity conditions of the model are fulfilled, the association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is now indeed controlled for the confounder <span class="math inline">\(C\)</span>. After all, <span class="math display">\[\begin{eqnarray*}
\beta_1&amp;=&amp;\alpha + \beta_1 (x+1) +\beta_2 c-\alpha - \beta_1 x -\beta_2 c \\
&amp;=&amp;E(Y|X=x+1,C=c)-E(Y|X=x,C=c) \,.
\end{eqnarray*}\]</span> In other words, <span class="math inline">\(\beta_1\)</span> represents the mean difference in outcome between individuals that differ 1 unit in <span class="math inline">\(X\)</span>, but all have the same value for the confounder <span class="math inline">\(C\)</span> (e.g., people of the same age). This way we compare comparable groups of individuals, effectively correcting for the perturbing effect of the confounder. In the literature, the estimate for <span class="math inline">\(\beta_1\)</span> is therefore called the <em>adjusted effect</em> of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, to indicate that we controlled for confounders. If <span class="math inline">\(C\)</span> is the only confounder<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> for the association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, then this can indeed be interpreted as the causal effect of an increase of 1 unit of <span class="math inline">\(X\)</span> on the mean outcome. The estimate for the association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> in the model without confounders (i.e., the estimate <span class="math inline">\(\beta^*_1\)</span> in the model <span class="math inline">\(E(Y|X)=\alpha^*+\beta^*_1X\)</span>) is then called the <em>unadjusted effect</em> of <span class="math inline">\(X\)</span> on <span class="math inline">\(Y\)</span>, even though it has, due to confounding, no causal meaning (in other words, it does not represent an effect of a unit change in <span class="math inline">\(X\)</span> on the mean outcome).</p>
<p>In some cases we would also like to know if the effect of a variable <span class="math inline">\(X\)</span> on another variable <span class="math inline">\(Y\)</span> depends on a third variable <span class="math inline">\(C\)</span>. This could, for example, happen when we wish to investigate if the effect of asbestos on the respiratory function changes with increasing age. Such issues are very relevant in the context of scientific studies on gene-environment interactions. For asthma or COPD, for example, there are strong indications that gene-environment interactions with a history of smoking are important factors in determining the severity of the disease (in particular that the role of certain genes is amplified by a history of smoking). In pharmacogenetics there exists a huge interest in gene-medicine interactions in order to ascertain if certain drugs are especially effective in the presence of certain genes. For example, gene-medicine interactions were discovered for steroids with regard to their effect on the respiratory function of asthma patients.</p>
<p>To statistically model such <em>interaction</em> or <em>effect modification</em> between 2 variables <span class="math inline">\(X\)</span> (e.g., use of steroids or not) and <span class="math inline">\(C\)</span> (e.g., presence/absence of a certain gene), we could add the product of those variables to the model: <span class="math display">\[
    E(Y|X,C)=\alpha+\beta_1X+\beta_2C+\beta_3 X C.
\]</span> The effect of a change in <span class="math inline">\(X\)</span> on the mean outcome now is <span class="math display">\[\begin{eqnarray*}
E(Y|X=x+1,C=c)-E(Y|X=x,C=c)&amp;=&amp;\alpha + \beta_1 (x+1) +\beta_2 c+\beta_3
(x+1)c \\
&amp;&amp;-\alpha - \beta_1 x -\beta_2 c-\beta_3 xc \\
&amp;=&amp;\beta_1+\beta_3c
\end{eqnarray*}\]</span> when <span class="math inline">\(C\)</span> remains unchanged. Remark that the effect of a change in <span class="math inline">\(X\)</span> for a constant value of <span class="math inline">\(C\)</span> now indeed depends on the chosen value of <span class="math inline">\(C\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mineral composition vs growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>The regression model <span id="eq-model-no-interaction"><span class="math display">\[
    E(Y|X_n,X_f)=\alpha+\beta_n X_n+\beta_f X_f
\tag{2.5}\]</span></span> assumes that nitrogen and phosphorus are linearly associated with the length of Japanese larches, but that the strength of the association between nitrogen and length does not depend on the phosphorus level in the needles. This model is described in R as</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>model_no_interaction <span class="ot">&lt;-</span> <span class="fu">lm</span>(length <span class="sc">~</span> nitrogen <span class="sc">+</span> phosphor, <span class="at">data =</span> needles)</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_no_interaction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = length ~ nitrogen + phosphor, data = needles)

Residuals:
    Min      1Q  Median      3Q     Max 
-57.834 -34.950  -0.539  20.364 127.287 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -189.64      42.53  -4.460 0.000179 ***
nitrogen      123.83      26.62   4.652 0.000111 ***
phosphor      604.44     162.65   3.716 0.001135 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 45.25 on 23 degrees of freedom
Multiple R-squared:  0.7934,    Adjusted R-squared:  0.7755 
F-statistic: 44.17 on 2 and 23 DF,  p-value: 1.329e-08</code></pre>
</div>
</div>
<p>In particular, the output suggests that trees that differ 0.1% in their nitrogen level, but have the same level of phosphorus, differ on average 0.12 m in length, regardless from the actual level of phosphorus. <a href="#fig-needles-no-interaction" class="quarto-xref">Figure&nbsp;<span>2.9</span></a> (left) illustrates indeed that the mean tree length increases at the same rate with an increase of the level of nitrogen, irrespective of the level of phosphorus in the needles. Similarly, <a href="#fig-needles-no-interaction" class="quarto-xref">Figure&nbsp;<span>2.9</span></a> (right) shows that the association between tree length and nitrogen is 123.8, no matter what the level of phosphorus is.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>model_no_interaction <span class="ot">&lt;-</span> <span class="fu">lm</span>(length <span class="sc">~</span> nitrogen <span class="sc">+</span> phosphor, <span class="at">data =</span> needles)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>nitrogen_plot <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">50</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>phosphor_plot <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.10</span>, <span class="fl">0.20</span>, <span class="fl">0.30</span>, <span class="fl">0.40</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>predict_length <span class="ot">&lt;-</span> <span class="cf">function</span>(phosphor) {</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(model_no_interaction, <span class="at">new =</span> <span class="fu">data.frame</span>(</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">phosphor =</span> phosphor,</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">nitrogen =</span> nitrogen_plot))</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span>, <span class="at">type=</span><span class="st">'n'</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="fu">min</span>(nitrogen_plot), <span class="fu">max</span>(nitrogen_plot)),</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">300</span>), <span class="at">xlab=</span><span class="st">'Nitrogen'</span>, <span class="at">ylab=</span><span class="st">'Length'</span>,</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Nitrogen-length Association"</span>)</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (ph <span class="cf">in</span> phosphor_plot) {</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>  outcome <span class="ot">&lt;-</span> <span class="fu">predict_length</span>(ph)</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(nitrogen_plot, outcome, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a><span class="co"># manually place labels</span></span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.35</span>, <span class="dv">150</span>, <span class="fl">0.10</span>, <span class="at">adj =</span> <span class="dv">0</span>)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.07</span>, <span class="dv">177</span>, <span class="fl">0.20</span>, <span class="at">adj =</span> <span class="dv">0</span>)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">1.79</span>, <span class="dv">203</span>, <span class="fl">0.30</span>, <span class="at">adj =</span> <span class="dv">0</span>)</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">1.50</span>, <span class="dv">230</span>, <span class="fl">0.40</span>, <span class="at">adj =</span> <span class="dv">0</span>)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>cs <span class="ot">&lt;-</span> <span class="fu">coef</span>(model_no_interaction)</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>phosphor_plot <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.15</span>, <span class="fl">0.40</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>nitrogen_effect <span class="ot">&lt;-</span> cs[<span class="dv">2</span>] <span class="sc">+</span> <span class="dv">0</span><span class="sc">*</span>phosphor_plot</span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(phosphor_plot, nitrogen_effect, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Phosphorus"</span>, <span class="at">ylab =</span> <span class="st">"Nitrogen effect"</span>,</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Influence of one unit of nitrogen"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-needles-no-interaction" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-needles-no-interaction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-needles-no-interaction-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-needles-no-interaction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.9: Association between tree length and levels of nitrogen and phosphorus in model <a href="#eq-model-no-interaction" class="quarto-xref"><span>2.5</span></a>. Left: mean tree length in function of nitrogen level for different levels of phosphorus. Right: size of the association between nitrogen and tree length for different levels of phosphorus.
</figcaption>
</figure>
</div>
</div>
</div>
<p>The linear regression model <span id="eq-interaction"><span class="math display">\[
    E(Y|X_n,X_f)=\alpha+\beta_n X_n+\beta_f X_f+\beta_{nf} X_nX_f
\tag{2.6}\]</span></span> also assumes that nitrogen and phosphorus are linearly associated with the length of Japanese larches, but allows the association between nitrogen and length to vary with the level of phosphorus in the needles. This model is described in R as</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>model_interaction <span class="ot">&lt;-</span> <span class="fu">lm</span>(length <span class="sc">~</span> nitrogen<span class="sc">*</span>phosphor, <span class="at">data =</span> needles)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_interaction)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = length ~ nitrogen * phosphor, data = needles)

Residuals:
    Min      1Q  Median      3Q     Max 
-57.533 -32.025   0.205  23.121 107.795 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)  
(Intercept)         198.42     211.94   0.936   0.3593  
nitrogen            -79.04     111.67  -0.708   0.4865  
phosphor           -971.01     858.65  -1.131   0.2703  
nitrogen:phosphor   794.97     426.20   1.865   0.0755 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 42.99 on 22 degrees of freedom
Multiple R-squared:  0.8216,    Adjusted R-squared:  0.7973 
F-statistic: 33.78 on 3 and 22 DF,  p-value: 2.057e-08</code></pre>
</div>
</div>
<p>In particular, the output suggests that trees that differ by 0.1% in nitrogen level, but with the same level of phosphorus <span class="math inline">\(x_f\)</span>, differ on average by <span class="math inline">\(-7.9+79.5x_f\)</span> centimeter in length. Trees with a phosphorus level of 0.1% will therefore have approximately the same length, irrespective of their level of nitrogen (because <span class="math inline">\(-0.79+7.95\times 0.1\approx 0\)</span>). Trees that differ 0.1% in nitrogen level and have a phosphorus level of 0.2%, will on average differ <span class="math inline">\(-7.9+79.5\times 0.2=8\)</span> cm in length. <a href="#fig-needles-interaction" class="quarto-xref">Figure&nbsp;<span>2.10</span></a> (left) shows indeed that the mean tree length grows at different rates with increasing levels of nitrogen, depending on the phosphorus level. Similarly, <a href="#fig-needles-interaction" class="quarto-xref">Figure&nbsp;<span>2.10</span></a> (right) illustrates that the association between tree length and nitrogen changes linearly according to the expression <span class="math inline">\(-7.9+79.5x_f\)</span> in function of the level of phosphorus <span class="math inline">\(x_f\)</span>. In particular, the influence of nitrogen increases when the needles contain more phosphorus.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model_interaction <span class="ot">&lt;-</span> <span class="fu">lm</span>(length <span class="sc">~</span> nitrogen<span class="sc">*</span>phosphor, <span class="at">data =</span> needles)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>nitrogen_plot <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">50</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>phosphor_plot <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.15</span>, <span class="fl">0.20</span>, <span class="fl">0.25</span>, <span class="fl">0.30</span>)</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>predict_length <span class="ot">&lt;-</span> <span class="cf">function</span>(phosphor) {</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">predict</span>(model_interaction, <span class="at">new =</span> <span class="fu">data.frame</span>(</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">phosphor =</span> phosphor,</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">nitrogen =</span> nitrogen_plot))</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="dv">1</span>, <span class="at">type=</span><span class="st">'n'</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="fu">min</span>(nitrogen_plot), <span class="fu">max</span>(nitrogen_plot)),</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">300</span>), <span class="at">xlab=</span><span class="st">'Nitrogen'</span>, <span class="at">ylab=</span><span class="st">'Length'</span>,</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>     <span class="at">main=</span><span class="st">"Nitrogen-length association"</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (ph <span class="cf">in</span> phosphor_plot) {</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>  outcome <span class="ot">&lt;-</span> <span class="fu">predict_length</span>(ph)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lines</span>(nitrogen_plot, outcome, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co"># manually place labels</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.55</span>, <span class="dv">150</span>, <span class="fl">0.15</span>, <span class="at">adj =</span> <span class="dv">0</span>)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.55</span>, <span class="dv">200</span>, <span class="fl">0.20</span>, <span class="at">adj =</span> <span class="dv">0</span>)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.55</span>, <span class="dv">250</span>, <span class="fl">0.25</span>, <span class="at">adj =</span> <span class="dv">0</span>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">2.10</span>, <span class="dv">280</span>, <span class="fl">0.30</span>, <span class="at">adj =</span> <span class="dv">0</span>)</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>cs <span class="ot">&lt;-</span> <span class="fu">coef</span>(model_interaction)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>phosphor_plot <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.15</span>, <span class="fl">0.40</span>, <span class="at">by =</span> <span class="fl">0.1</span>)</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>nitrogen_effect <span class="ot">&lt;-</span> cs[<span class="dv">2</span>] <span class="sc">+</span> cs[<span class="dv">4</span>]<span class="sc">*</span>phosphor_plot</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(phosphor_plot, nitrogen_effect, <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Phosphorus"</span>, <span class="at">ylab =</span> <span class="st">"Nitrogen effect"</span>,</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Influence of one unit of nitrogen"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-needles-interaction" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-needles-interaction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-needles-interaction-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-needles-interaction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.10: Association between tree length and levels of nitrogen and phosphorus in model ( ef{eq:regrint2}). Left: mean tree length in function of nitrogen level for different levels of phosphorus. Right: size of the association between nitrogen and tree length for different levels of phosphorus.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<p>Finally, we wish to remark that residual plots similar to the ones used for simple linear regression models can be used to verify the linearity assumption for multiple linear regression models. However, since the model now contains multiple predictors, it makes sense to plot the residuals and squared residuals in function of each of the predictors separately. In that way we can verify with respect to which variable the linearity of the model might fail. To avoid too much work in models with a lot of predictors, we sometimes also plot the residuals in function of the predictions <span class="math inline">\(\hat{\alpha}+\hat{\beta}_1x_1+...+\hat{\beta}_px_p\)</span>. After all, if we note a deviation with respect to the predictions, then that deviation also holds with respect to at least 1 of the predictors (since the predictions are function of the predictors).</p>
</section>
<section id="inference-in-regression-models-and-model-construction" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="inference-in-regression-models-and-model-construction"><span class="header-section-number">2.7</span> Inference in regression models and model construction</h2>
<p>In practice we often possess a large number of predictors and it is therefore not always obvious what regression model to consider. After all, such a model does not necessarily contain just the predictors separately, but possibly also higher order terms when one of the predictors is not linearly associated with the outcome, or interactions between 2 predictors when there is an indication that the effect of a certain predictor depends on the value of another predictor. All in all, there are in practice easily thousands of possible models that could have generated the data.</p>
<p>Hoping to obtain a model that is as accurate as possible, we could opt to include as many predictors as possible in the model, together with their interactions and higher order terms. However, such a strategy comes with big disadvantages. First of all, the final model will contain an enormous amount of predictors. This means that based on a limited number of observations, a lot of parameters need to be estimated, leading to imprecise estimates. With this we mean that, if we would repeat the study in a similar way, the results for the regression parameters can vary strongly between samples and that there is thus a big risk that they deviate greatly from the true population values. Secondly, coefficients in models with higher order terms and interactions are more difficult to interpret. This makes complex models less interesting for scientific purposes since in that case we pursue as much simplicity as possible (unless this would give incorrect models). After all, models that contain superfluous terms have the tendency, even if they are correct, to <em>overfit</em> the data. This means that predictions obtained by those models will give good approximations for those outcomes that have been observed, but bad approximations for outcomes that are observed in a similar sample that was not used to construct the regression model. Keeping these disadvantages in mind, we will strive to construct a model that is as simple as possible by preventing unimportant predictors from entering the model.</p>
<p>Starting from a given regression model <a href="#eq-mlinreg" class="quarto-xref"><span>2.4</span></a>, we can decide for each predictor <span class="math inline">\(x_j\)</span> whether or not it is essential in the model by testing the null hypothesis that the corresponding coefficient <span class="math inline">\(\beta_j=0\)</span> (versus a two-sided alternative). If the outcome is normally distributed for given values of the predictors or if the sample is sufficiently large, and if furthermore the variance on the outcomes is homogeneous (i.e., does not depend on the predictors), then such tests can relatively easy be obtained by using the knowledge that for each coefficient <span class="math inline">\(\beta_j\)</span> in the model <span class="math display">\[
    \frac{\hat{\beta}_j-\beta_j}{SE(\hat{\beta}_j)}\sim t_{n-p}
\]</span> where <span class="math inline">\(p\)</span> represents the number of unknown parameters in the model. We will not discuss the details on the calculation of the standard errors, but trust the software to estimate those for us. Confidence intervals for <span class="math inline">\(\beta_j\)</span> can also be obtained using this result.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mineral composition vs growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>Based on the linear regression model <a href="#eq-interaction" class="quarto-xref"><span>2.6</span></a> we can decide if there exists an indication that the measure in which tree length is associated with the nitrogen level in the needles, is also influenced by the presence of phosphorus. To gain this kind of insight, we can test whether <span class="math inline">\(\beta_{nf}=0\)</span> versus a two-sided alternative. Based on previous R-output, we find that the test statistic equals <span class="math inline">\(794.9668/426.1981=1.8653\)</span>. This value can also be directly found in the output under the output for t-value. For 26 available observations and 4 unknown parameters (intercept, 2 predictors and their interaction), we find that the corresponding p-value is the probability that a <span class="math inline">\(t_{22}\)</span>-distributed random variable is, in absolute value, more extreme than 1.8653. This probability equals 7.55% as can be seen in the output under <code>Pr(&gt;|t|)</code>. Hence, there is insufficient proof, at the 5% significance level, to conclude that the measure in which tree length is associated with the needles’ nitrogen level, is phosphorus-dependent. A 95% confidence interval for <span class="math inline">\(\beta_{sf}\)</span> is found as <span class="math display">\[
    794.9668\pm t_{22,0.025}\times 426.1981=[-88.91,1678.85]
\]</span> The interval allows for large effect modifications, because of which we cannot just conclude that the association between nitrogen and tree length is not phosphorus-dependent. The relatively small negative values suggest that a weak enfeeblement of the association between nitrogen and the tree length for increasing phosphorus values is compatible with the data. The positive values in the interval also suggest that a small to large strengthening of the association between nitrogen and the tree length for increasing levels of phosphorus is compatible with the data.</p>
</div>
</div>
<p>Whenever the aim of the regression model is to predict the outcomes based on the predictors or to describe associations between on the one hand the outcome and on the other hand the predictors, <em>automatic selection procedures</em> can often come in very handy. One of these procedures, the <em>stepwise selection procedure</em>, starts with a model that only contains the intercept. In the next step, the predictor that is most strongly associated with the outcome (in the sense that the corresponding regression parameter has the largest absolute t-value or the smallest p-value) is included in the model, provided that it is significantly associated with the outcome.</p>
<p>Starting from the resulting model, the predictor that is now most strongly associated with the outcome (in the sense that the corresponding regression parameter has the largest absolute t-value or the smallest p-value) is added. It is often advised to perform these tests at the 10% significance level to avoid that important predictors disappear from the model. Then the predictors that are no longer significantly associated with the outcome are, starting with the least significant, one by one removed from the model until we obtain a model with only significant predictors. Remark that predictors which were significantly associated with the outcome in previous steps can become insignificant due to confounding and similar reasons. Next, the predictor that is most strongly associated with the outcome is included in the new model. This algorithm is repeated until the model doesn’t change any more.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mineral composition vs growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>Simple regression models produced the following t-values: 6.97, 5.99, 6.35, and 5.87 for a model with respectively only nitrogen, only phosphorus, only potassium, and only residual ash. In a stepwise selection procedure, we will opt to first include nitrogen in the model. It is indeed retained, because it is significantly associated with the tree length at the 10% significance level. Adding respectively phosphorus, potassium or residual ash to the resulting model gives t-values of 3.72, 4.91, and 3.07. Based on these t-values, we now add potassium to the model. This gives the following output:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>m_nk <span class="ot">&lt;-</span> <span class="fu">lm</span>(length <span class="sc">~</span> nitrogen <span class="sc">+</span> potassium, <span class="at">data =</span> needles)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_nk)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = length ~ nitrogen + potassium, data = needles)

Residuals:
    Min      1Q  Median      3Q     Max 
-75.625 -30.298   5.557  27.527  61.897 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  -180.87      36.94  -4.896 6.04e-05 ***
nitrogen      123.26      22.41   5.499 1.36e-05 ***
potassium     188.69      38.40   4.913 5.79e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 39.98 on 23 degrees of freedom
Multiple R-squared:  0.8387,    Adjusted R-squared:  0.8247 
F-statistic: 59.79 on 2 and 23 DF,  p-value: 7.727e-10</code></pre>
</div>
</div>
<p>Both predictors nitrogen and potassium are significantly associated with the outcome and are thus retained in the model. This procedure continues until the model is stable. Once the first order structure is known (i.e., the algorithm has converged, but so far no higher order terms or interactions have been added), the same principle can be applied for higher order terms and interactions. Please note that this is applied hierarchically, meaning that lower order terms will never be removed from the model as long as the higher order terms are significantly associated with the outcome. Continuing in this way, we obtain the model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>m_needles_full <span class="ot">&lt;-</span> <span class="fu">lm</span>(length <span class="sc">~</span> nitrogen <span class="sc">+</span> phosphor <span class="sc">+</span> potassium <span class="sc">+</span> residu <span class="sc">+</span> phosphor<span class="sc">:</span>residu <span class="sc">+</span> phosphor<span class="sc">:</span>nitrogen, <span class="at">data =</span> needles)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_needles_full)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = length ~ nitrogen + phosphor + potassium + residu + 
    phosphor:residu + phosphor:nitrogen, data = needles)

Residuals:
    Min      1Q  Median      3Q     Max 
-57.559 -18.976   0.007  11.608  55.941 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)         129.09     169.33   0.762   0.4552   
nitrogen           -150.76      97.08  -1.553   0.1369   
phosphor          -1000.02     682.98  -1.464   0.1595   
potassium           137.97      41.24   3.346   0.0034 **
residu              193.80      89.10   2.175   0.0425 * 
phosphor:residu    -598.08     290.02  -2.062   0.0531 . 
nitrogen:phosphor   951.78     371.57   2.562   0.0191 * 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 33.43 on 19 degrees of freedom
Multiple R-squared:  0.9069,    Adjusted R-squared:  0.8774 
F-statistic: 30.83 on 6 and 19 DF,  p-value: 8.159e-09</code></pre>
</div>
</div>
<p>Remark that nitrogen and phosphorus, although not significantly associated with tree length at the 10% significance level, are retained in the model because these terms appear in higher order terms (i.e., <code>phosphorus:nitrogen</code>). As an exercise, think about how the parameters in this “final model” can be interpreted.</p>
</div>
</div>
<p>Although the previously described algorithm offers a relatively simple and natural way to construct models, this strategy also has its disadvantages. It relies upon a large number of hypothesis tests and is therefore extremely sensitive to the problem of multiple testing. The risk with this is that predictors that are insignificant at population level will be included in the model because by chance they seem to be associated with the outcome in the sample. Keeping this in mind, it is wise to avoid the problem of multiple testing in practice by not exhaustively considering all possible higher order terms and interactions, but first make a limited selection of higher order terms and interactions that might be plausible, based on biological judgment and insight gained from diagnostic plots.</p>
<p>In recent years, several alternative techniques for model construction have been developed in the domain of machine learning which are based on <em>cross validation</em>. In short, cross validation is a technique where the regression model is repeatedly estimated based on a (varying) subset of the observations and its performance is then evaluated based on how well it predicts the remaining observations.</p>
<p>So far we considered situations where the aim of the regression model consisted in predicting the outcome or describing associations. If the goal of the regression model is to estimate the causal effect of a certain exposure (e.g., exposure to asbestos) on a certain outcome (e.g., respiratory function), then of course this exposure certainly needs to be part of the model and what remains is to make sure that all confounders for the association between both are included in the model. Recall that confounders are measurements that are at the same time associated with the exposure and the outcome, but which are influenced by neither. In this case it is important to try to form an idea (based on biological insights) of what possible confounders there are and to certainly not include any consequences of the exposure or the outcome in the regression model. Because of this, it is often not advisable to apply automatic selection procedures in this situation. Expected confounders that turn out to be not significantly associated with the outcome can, of course, still be removed one by one from the model.</p>
<p>Finally we like to remark that the previously mentioned hypothesis tests are all based on the assumption of normally distributed outcomes for a given predictor value (unless the sample is sufficiently large) and that the variance is homogeneous in the predictors. Residual plots can be used to verify these assumptions. Since the model now contains multiple predictors, it makes sense to plot the squared residuals against each of these predictors separately or against the predictions <span class="math inline">\(\hat{\alpha}+\hat{\beta}_1x_1+...+\hat{\beta}_px_p\)</span> obtained by the model.</p>
</section>
<section id="regression-diagnostics" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="regression-diagnostics"><span class="header-section-number">2.8</span> Regression diagnostics</h2>
<section id="multicollinearity" class="level3" data-number="2.8.1">
<h3 data-number="2.8.1" class="anchored" data-anchor-id="multicollinearity"><span class="header-section-number">2.8.1</span> Multicollinearity</h3>
<p>An important problem in multiple linear regression, and one that is often overlooked, is the impact of correlated predictor variables on parameter estimates and on hypothesis tests concerning these parameters. When the predictors are correlated, as is often the case for biological data, we say that the data are subject to <em>multicollinearity</em>. Heavy multicollinearity can have a serious impact on the estimated regression parameters. After all, when 2 predictors are strongly correlated, they share for a large part the same information and it thus becomes difficult to estimate the separate effects of both on the outcome. This is expressed by the fact that the calculations of the least squares estimates become numerically unstable in the sense that small modifications to the data or even adding or removing a predictor variable will have a huge impact on the size, and possibly even the sign, of the estimated regression coefficients. A second effect of multicollinearity is that the standard errors of the estimated regression coefficients can be largely inflated and the corresponding confidence intervals thus become very wide. However, as long as we only try to make predictions based on the regression model without extrapolating outside the range of the predictors, multicollinearity does not pose a problem.</p>
<p>Problems caused by multicollinearity can be recognised by the fact that results become numerically unstable. Large changes can occur in the coefficients after inclusion of a predictor, very wide confidence intervals can be obtained for some coefficients, or unexpected results can be found. Formally, we can get an idea of the measure of multicollinearity by inspecting the correlations between each pair of predictors in the regression model or through a <em>scatterplot matrix</em> that plots each pair of predictors on a scatterplot. However, such diagnostics for multicollinearity are not ideal. First of all, they give no information on how unstable the results become by the observed multicollinearity. Secondly, in models with 3 or more predictors, let’s say <span class="math inline">\(X_1,X_2,X_3\)</span>, it can happen that heavy multicollinearity exists, despite the fact that all pairwise correlations between predictors are low. This could happen, for example, when <span class="math inline">\(X_1\)</span> is strongly correlated with a linear combination of <span class="math inline">\(X_2\)</span> and <span class="math inline">\(X_3\)</span>.</p>
<p>These mentioned disadvantages can be avoided by investigating the , which is defined for the <span class="math inline">\(k^{th}\)</span> coefficient in the regression model as <span class="math display">\[
    \textrm{VIF}_k=\left(1-R_k^2\right)^{-1}.
\]</span> In this expression, <span class="math inline">\(R_k^2\)</span> represents the multiple correlation coefficient of a linear regression model for the <span class="math inline">\(k^{th}\)</span> predictor based on all other predictors in the model. The VIF has the property that it equals 1 if the <span class="math inline">\(k^{th}\)</span> predictor is not linearly associated with the other predictors in the model, and consequently when the <span class="math inline">\(k^{th}\)</span> coefficient in the model is not subject to multicollinearity. The VIF is larger than 1 in all other cases. In particular, it expresses how much larger the observed variance on the estimate of the <span class="math inline">\(k^{th}\)</span> coefficient would be compared to when all predictors would be independent. Therefore, the larger the VIF, the less stable the estimates will be. The average of the VIFs for the different predictors can, up to a proportionality factor, be interpreted as the mean squared distance between the estimated coefficients and the true coefficients in the model. The smaller the VIF, the closer the estimates are thus expected to be to their population values. In practice, multicollinearity for a regression coefficient is considered problematic when its VIF surpasses 10.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Prediction of body fat
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is relatively laborious and costly to determine the proportion of body fat in a person. For that reason, a number of studies have been set up in the past in order to unravel the pattern between the true percentage of body fat and several, more easily measurable, surrogates. One of these studies measured for 20 healthy women between the ages of 25 and 34 years the proportion of body fat <span class="math inline">\(Y\)</span>, the thickness of the triceps skin fold <span class="math inline">\(X_1\)</span>, the thigh circumference <span class="math inline">\(X_2\)</span>, and the midarm circumference <span class="math inline">\(X_3\)</span>. Pairwise scatter plots for this dataset are shown in <a href="#fig-scattermatrix" class="quarto-xref">Figure&nbsp;<span>2.11</span></a>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>bodyfat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"./datasets/02-PCA/bodyfatNKNW.txt"</span>, <span class="at">sep =</span> <span class="st">' '</span>)</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>features <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"triceps.skinfold.thickness"</span>,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>              <span class="st">"thigh.circumference"</span>,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>              <span class="st">"midarm.circumference"</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a><span class="fu">pairs</span>(bodyfat[features])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-scattermatrix" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-scattermatrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-scattermatrix-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scattermatrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.11: Scatterplot matrix for the bodyfat dataset.
</figcaption>
</figure>
</div>
</div>
</div>
<p>If we are able to construct an accurate regression model based on these data, it will allow us in the future to make predictions of the proportion of body fat for healthy women between 25 and 34 years old, based on their triceps skin fold thickness, their thigh circumference, and their midarm circumference.</p>
<p>Including these 3 predictors simultaneously in the regression model gives the following model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>m_bodyfat <span class="ot">&lt;-</span> <span class="fu">lm</span>(bodyfat <span class="sc">~</span> triceps.skinfold.thickness <span class="sc">+</span> thigh.circumference <span class="sc">+</span> midarm.circumference, <span class="at">data =</span> bodyfat)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_bodyfat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = bodyfat ~ triceps.skinfold.thickness + thigh.circumference + 
    midarm.circumference, data = bodyfat)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.7263 -1.6111  0.3923  1.4656  4.1277 

Coefficients:
                           Estimate Std. Error t value Pr(&gt;|t|)
(Intercept)                 117.085     99.782   1.173    0.258
triceps.skinfold.thickness    4.334      3.016   1.437    0.170
thigh.circumference          -2.857      2.582  -1.106    0.285
midarm.circumference         -2.186      1.595  -1.370    0.190

Residual standard error: 2.48 on 16 degrees of freedom
Multiple R-squared:  0.8014,    Adjusted R-squared:  0.7641 
F-statistic: 21.52 on 3 and 16 DF,  p-value: 7.343e-06</code></pre>
</div>
</div>
<p>The scatterplot matrix in <a href="#fig-scattermatrix" class="quarto-xref">Figure&nbsp;<span>2.11</span></a> indicates that there is multicollinearity in terms of the predictors <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, but not immediately for the midarm circumference <span class="math inline">\(X_3\)</span>. Nevertheless we obtain substantial VIF values of respectively 708.84, 564.34, and 104.61 for the 3 predictors. This suggests that also the midarm circumference is susceptible to severe multicollinearity and hence shows that the scatterplot matrix indeed only gives a limited view on the problem of multicollinearity. On average, the VIF is 460, which shows that the mean (squared) distance between the estimates of the regression parameters and their true values is 460 times as large as when there would be no multicollinearity. In other words, there is a large problem of multicollinearity. This can also be observed in the regression output: not a single of the predictors is significantly associated with body fat, although the F-statistic<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> indicates, with a p-value of <span class="math inline">\(7.34 \ 10^{-6}\)</span>, that at for least 1 of the predictors there is strong evidence for an association with the outcome.</p>
</div>
</div>
<p>In the literature, numerous suggestions have been made for how to deal with the problem of multicollinearity. The most simple solution is to ban predictors that are strongly correlated with other predictors from the model. This makes sense when multiple predictors measure the same or a similar biological entity (e.g., a number of strongly correlated morphological traits). In other cases this might introduce a severe bias, namely when the predictor that is deleted from the model is an important confounder for the association between one of the remaining predictors and the outcome. Another approach, called <em>principal component regression</em>, roughly consists in transforming the predictors to a series of uncorrelated predictors, which solves the problem of multicollinearity. A third option, for example used in <em>ridge regression</em>, will allow that the estimates of the regression parameters are slightly biased in favour of a large increase in stability.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mineral composition vs growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>The addition of higher order and interaction terms to the model typically introduces multicollinearity problems since normally a predictor <span class="math inline">\(X_1\)</span> is correlated with any function, e.g., <span class="math inline">\(X_1X_2\)</span> or <span class="math inline">\(X_1^2\)</span>, of itself. In the previous section we constructed a model that included interactions between phosphorus and nitrogen as well as between phosphorus and residual ash. It therefore doesn’t come as a surprise that <a href="#fig-vif" class="quarto-xref">Figure&nbsp;<span>2.12</span></a> (left) shows large VIFs, especially for the interaction terms. In such situations, namely when the model contains interactions and higher order terms, it typically helps to center the concerned variables. To this end, the concerned predictors are transformed by subtracting their respective sample mean. For example, <span class="math inline">\(X_n\)</span> will be transformed to <span class="math inline">\(X_n-\bar X_n\)</span> and will be denoted by <code>cnitrogen</code> in the R code. Note that in <a href="#fig-vif" class="quarto-xref">Figure&nbsp;<span>2.12</span></a> (right) the problem of multicollinearity essentially has disappeared for the model that contains only these <em>centered variables</em>. Furthermore, the standard errors on the estimated regression coefficients have shrunk tremendously as can be seen in the output.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>needles_centered <span class="ot">&lt;-</span> <span class="fu">with</span>(needles, {</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>(</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">length =</span> length,</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">cnitrogen =</span> nitrogen <span class="sc">-</span> <span class="fu">mean</span>(nitrogen),</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">cphosphorus =</span> phosphor <span class="sc">-</span> <span class="fu">mean</span>(phosphor),</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">cpotassium =</span> potassium <span class="sc">-</span> <span class="fu">mean</span>(potassium),</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">cresidu =</span> residu <span class="sc">-</span> <span class="fu">mean</span>(residu))})</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>m_needles_full_centered <span class="ot">&lt;-</span> <span class="fu">lm</span>(</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    length <span class="sc">~</span> cnitrogen <span class="sc">+</span> cphosphorus <span class="sc">+</span> cpotassium <span class="sc">+</span> cresidu <span class="sc">+</span> cphosphorus<span class="sc">:</span>cresidu <span class="sc">+</span> cphosphorus<span class="sc">:</span>cnitrogen, <span class="at">data =</span> needles_centered)</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_needles_full_centered)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = length ~ cnitrogen + cphosphorus + cpotassium + 
    cresidu + cphosphorus:cresidu + cphosphorus:cnitrogen, data = needles_centered)

Residuals:
    Min      1Q  Median      3Q     Max 
-57.559 -18.976   0.007  11.608  55.941 

Coefficients:
                      Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)            188.933      9.013  20.963 1.35e-14 ***
cnitrogen               87.731     22.431   3.911 0.000939 ***
cphosphorus            273.664    152.171   1.798 0.088022 .  
cpotassium             137.966     41.237   3.346 0.003397 ** 
cresidu                 43.938     34.908   1.259 0.223398    
cphosphorus:cresidu   -598.078    290.020  -2.062 0.053134 .  
cnitrogen:cphosphorus  951.782    371.568   2.562 0.019086 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 33.43 on 19 degrees of freedom
Multiple R-squared:  0.9069,    Adjusted R-squared:  0.8774 
F-statistic: 30.83 on 6 and 19 DF,  p-value: 8.159e-09</code></pre>
</div>
</div>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(car)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>필요한 패키지를 로딩중입니다: carData</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">vif</span>(m_needles_full), <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">xlab =</span> <span class="st">"Parameter number"</span>, <span class="at">ylab =</span> <span class="st">"VIF"</span>, <span class="at">main =</span> <span class="st">"Before centering"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>there are higher-order terms (interactions) in this model
consider setting type = 'predictor'; see ?vif</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">10</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">vif</span>(m_needles_full_centered), <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">xlab =</span> <span class="st">"Parameter number"</span>, <span class="at">ylab =</span> <span class="st">"VIF"</span>, <span class="at">main =</span> <span class="st">"After centering"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>there are higher-order terms (interactions) in this model
consider setting type = 'predictor'; see ?vif</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-vif" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vif-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-vif-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vif-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.12: Variance inflation factors before (left) and after (right) centering. Parameter numbers 1 to 6 correspond respectively with <span class="math inline">\(X_n, X_f, X_p, X_r, X_fX_r\)</span> and <span class="math inline">\(X_fX_n\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="influential-observations" class="level3" data-number="2.8.2">
<h3 data-number="2.8.2" class="anchored" data-anchor-id="influential-observations"><span class="header-section-number">2.8.2</span> Influential observations</h3>
<p>Often, a dataset contains extreme observations, both for the outcome <span class="math inline">\(Y\)</span> and the predictors <span class="math inline">\(X\)</span>. These extreme observations can greatly influence the estimated regression parameters and regression line. This is no surprise, since the regression line represents the mean outcome in function of <span class="math inline">\(X\)</span> and the mean is sensitive to outliers.</p>
<p><a href="#fig-outliers" class="quarto-xref">Figure&nbsp;<span>2.13</span></a> shows the possible influence of extreme observations, or outliers, on the regression line. Plot (a) shows a synthetic dataset consisting of 10 observations together with the regression line. The other plots show what happens to the regression line when one outlier, displayed in red, is added. In each case, we show the unmodified regression line (dashed line) and the regression line when the outlier is added (solid line).</p>
<p>The outlier in plot (b) follows the pattern of the unmodified regression line, and hence does not affect the regression line appreciably. We say that this point has high leverage (it has the potential of affecting the regression line), but low influence (its actual effect is small). We will make this more precise later on.Plot (c) shows an outlier with an extreme <span class="math inline">\(y\)</span>-value, but whose <span class="math inline">\(x\)</span>-value is close to the mean of the dataset. We will see that such outliers have low leverage: their potential to affect the regression line is low. Lastly, plot(d) shows an outlier with a large influence on the regression line. While the <span class="math inline">\(y\)</span>-value of the outlier is not that extreme, the <span class="math inline">\(x\)</span>-value is, and the regression line is noticeably affected.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">12345</span>)  </span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>make_data <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">n =</span> <span class="dv">10</span>) {</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="dv">3</span><span class="sc">*</span><span class="fu">runif</span>(n))</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    Y <span class="ot">&lt;-</span> X <span class="sc">+</span> <span class="fl">0.3</span><span class="sc">*</span><span class="fu">rnorm</span>(n)</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.frame</span>(<span class="at">X =</span> X, <span class="at">Y =</span> Y)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">make_data</span>()</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>outlier1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.5</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>outlier2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">5</span>)</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>outlier3 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>make_plot <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">title =</span> <span class="cn">NULL</span>) {</span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(<span class="cn">NULL</span>, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">4</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">5</span>), <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">""</span>, <span class="at">main =</span> title)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>add_points <span class="ot">&lt;-</span> <span class="cf">function</span>(data, <span class="at">outlier =</span> <span class="cn">NULL</span>) {</span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">points</span>(Y <span class="sc">~</span> X, <span class="at">data =</span> data, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="sc">!</span><span class="fu">is.null</span>(outlier)) {</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>        <span class="fu">points</span>(outlier[<span class="dv">1</span>], outlier[<span class="dv">2</span>], <span class="at">pch =</span> <span class="dv">19</span>, <span class="at">col =</span> <span class="st">"red"</span>)</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>add_line <span class="ot">&lt;-</span> <span class="cf">function</span>(data, lty, <span class="at">outlier =</span> <span class="cn">NULL</span>) {</span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a>    m <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X, <span class="at">data =</span> <span class="fu">rbind</span>(data, outlier))</span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>    <span class="fu">abline</span>(m, <span class="at">lty =</span> lty)</span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb51-29"><a href="#cb51-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-30"><a href="#cb51-30" aria-hidden="true" tabindex="-1"></a><span class="fu">make_plot</span>(<span class="st">"(a) No outliers"</span>)</span>
<span id="cb51-31"><a href="#cb51-31" aria-hidden="true" tabindex="-1"></a><span class="fu">add_line</span>(data, <span class="st">"dashed"</span>)</span>
<span id="cb51-32"><a href="#cb51-32" aria-hidden="true" tabindex="-1"></a><span class="fu">add_points</span>(data)</span>
<span id="cb51-33"><a href="#cb51-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-34"><a href="#cb51-34" aria-hidden="true" tabindex="-1"></a><span class="fu">make_plot</span>(<span class="st">"(b) High leverage, low influence"</span>)</span>
<span id="cb51-35"><a href="#cb51-35" aria-hidden="true" tabindex="-1"></a><span class="fu">add_line</span>(data, <span class="st">"dashed"</span>)</span>
<span id="cb51-36"><a href="#cb51-36" aria-hidden="true" tabindex="-1"></a><span class="fu">add_line</span>(data, <span class="st">"solid"</span>, <span class="at">outlier =</span> outlier1)</span>
<span id="cb51-37"><a href="#cb51-37" aria-hidden="true" tabindex="-1"></a><span class="fu">add_points</span>(data, <span class="at">outlier =</span> outlier1)</span>
<span id="cb51-38"><a href="#cb51-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-39"><a href="#cb51-39" aria-hidden="true" tabindex="-1"></a><span class="fu">make_plot</span>(<span class="st">"(c) Low leverage"</span>)</span>
<span id="cb51-40"><a href="#cb51-40" aria-hidden="true" tabindex="-1"></a><span class="fu">add_line</span>(data, <span class="st">"dashed"</span>)</span>
<span id="cb51-41"><a href="#cb51-41" aria-hidden="true" tabindex="-1"></a><span class="fu">add_line</span>(data, <span class="st">"solid"</span>, <span class="at">outlier =</span> outlier2)</span>
<span id="cb51-42"><a href="#cb51-42" aria-hidden="true" tabindex="-1"></a><span class="fu">add_points</span>(data, <span class="at">outlier =</span> outlier2)</span>
<span id="cb51-43"><a href="#cb51-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-44"><a href="#cb51-44" aria-hidden="true" tabindex="-1"></a><span class="fu">make_plot</span>(<span class="st">"(d) High leverage, high influence"</span>)</span>
<span id="cb51-45"><a href="#cb51-45" aria-hidden="true" tabindex="-1"></a><span class="fu">add_line</span>(data, <span class="st">"dashed"</span>)</span>
<span id="cb51-46"><a href="#cb51-46" aria-hidden="true" tabindex="-1"></a><span class="fu">add_line</span>(data, <span class="st">"solid"</span>, <span class="at">outlier =</span> outlier3)</span>
<span id="cb51-47"><a href="#cb51-47" aria-hidden="true" tabindex="-1"></a><span class="fu">add_points</span>(data, <span class="at">outlier =</span> outlier3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-outliers" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-outliers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-outliers-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-outliers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.13: Influence of outliers on the regression line. Figure (a): original dataset and regression line. Figure (b): Outlier with high leverage but low influence on the regression line. Figure (c): Outlier with low leverage. Figure (d): Outlier with large leverage and large influence.
</figcaption>
</figure>
</div>
</div>
</div>
<p>It is in general undesirable that a single observation has an outsized influence of the results of a linear regression analysis. Some diagnostics to track down extreme observations are therefore needed. <em>Residuals</em> indicate how much the outcome differs from the regression line and can thus be used to identify extreme outcomes. In particular, we already mentioned that residuals should be approximately normally distributed when the model is correct and the outcome is normally distributed (for fixed predictor values) with a homogeneous variance. Verifying whether or not a residual is extreme can then be done by comparing it to the normal distribution. Assume, for example, that we have a dataset with 100 observations. We then expect that approximately 95% of the residuals are, in absolute value, smaller than 1.96<span class="math inline">\(\hat{\sigma}\)</span>. Observing a lot more than 5% of extreme residuals will then give us an indication for outliers.</p>
<p>In the literature, a number of modifications of the residuals have been introduced to make them more suitable for outlier detection. After all, it is possible to show that, due to estimation errors, even when the model is correct and the outcomes are normally distributed (for fixed predictor values) with homogeneous variance, the residuals will not have a constant variance and are not perfectly normally distributed. <em>Studentized residuals</em> are a transformation of the previously defined residuals that do come with a constant variance and that are <span class="math inline">\(t\)</span>-distributed with <span class="math inline">\(n-1\)</span> degrees of freedom under the assumptions of the model. Outliers can thus be detected more accurately by verifying if a lot more than 5% of the Studentized residuals are larger in absolute value than the 97.5% percentile of the <span class="math inline">\(t_{n-1}\)</span>-distribution.</p>
<p>Extreme predictor values can in principle be detected using a scatterplot matrix of the outcome in function of the different predictors. However, when there are multiple predictors, these plots have serious shortcomings because it is possible that not the predictor values themselves, but a combination of the predictors is unusual, which may not be visible in these plots. It is therefore more sensible to investigate the so-called <em>leverage</em> (influence) of each observation. Leverage is a diagnostic measure for the influence of predictor observations (in contrast to residuals that give a diagnostic measure for the influence of the outcomes). In particular, the leverage of observation <span class="math inline">\(i\)</span> is a measure for the distance of the predictor value of observation <span class="math inline">\(i\)</span> to the mean predictor value in the sample. As a consequence, a large leverage for the <span class="math inline">\(i^{th}\)</span> observation means that it has predictor values that strongly deviate from the mean. In this case, that observation might also have a large influence on the regression coefficients and the predictions. Leverage values normally vary between <span class="math inline">\(1/n\)</span> and <span class="math inline">\(1\)</span> and are on average equal to <span class="math inline">\(p/n\)</span> with <span class="math inline">\(p\)</span> the number of unknown parameters. Typically, a leverage value is considered to be extreme if it is larger than <span class="math inline">\(2p/n\)</span>.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>leverage <span class="ot">&lt;-</span> <span class="fu">hatvalues</span>(m_needles_full)</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(leverage, <span class="at">xlab =</span> <span class="st">"Observation"</span>, <span class="at">ylab =</span> <span class="st">"Leverage"</span>, <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">coefficients</span>(m_needles_full))</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(needles)</span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="dv">2</span> <span class="sc">*</span> p <span class="sc">/</span> n, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-leverage" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-leverage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-leverage-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-leverage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.14: Leverage in function of observation number. The dashed line indicates the cut-off value of <span class="math inline">\(2p/n\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>A more direct measure to express the influence of each observation on the regression analysis, is <em>Cook’s distance</em>. The Cook’s distance for the <span class="math inline">\(i^{th}\)</span> observation is a diagnostic measure for the influence of that observation on all predictions, or equivalently for its influence on <em>all</em> estimated coefficients. It is obtained by comparing each prediction <span class="math inline">\(\hat{Y}_j\)</span>, obtained based on the regression model for the <span class="math inline">\(j^{th}\)</span> outcome, <span class="math inline">\(j=1, \ldots, n\)</span>, with the corresponding prediction <span class="math inline">\(\hat{Y}_{j(i)}\)</span> that would have been obtained if observation <span class="math inline">\(i\)</span> had not been used to fit the regression model: <span class="math display">\[
    D_i=\frac{\sum_{j=1}^n(\hat{Y}_j-\hat{Y}_{j(i)})^2}{p\textrm{MSE}}.
\]</span> If the Cook’s distance <span class="math inline">\(D_i\)</span> is large, then observation <span class="math inline">\(i\)</span> will have a large influence on the predictions and estimated coefficients. In particular, a Cook’s distance is called extreme if it surpasses the 50% percentile of the <span class="math inline">\(F_{p,n-p}\)</span>-distribution.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mineral composition vs growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>The leverage of each observation in the regression analysis for this example is shown in <a href="#fig-leverage" class="quarto-xref">Figure&nbsp;<span>2.14</span></a>. It indicates that the first and fourth observation take on extreme predictor values and hence might have a large influence on the results of the analysis. The Cook’s distance of the first observation is 1.5. Knowing that the model contains 7 parameters (<span class="math inline">\(p=7\)</span>) and 26 observations (<span class="math inline">\(n=26\)</span>), we conclude that this well exceeds the 50% percentile of the <span class="math inline">\(F_{p,n-p}\)</span>-distribution, which is 0.94. Essentially, the value of 1.5 corresponds to the 77% percentile of that distribution. We thus conclude that the first observation has a large influence on the estimated regression coefficients. <a href="#fig-cooks" class="quarto-xref">Figure&nbsp;<span>2.15</span></a> shows that the other observations have a far lesser and hardly influential impact.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">cooks.distance</span>(m_needles_full),</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Observation"</span>,</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Cook's distance"</span>)</span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fl">0.94</span>, <span class="at">col =</span> <span class="st">"blue"</span>, <span class="at">lty =</span> <span class="st">"dashed"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-cooks" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cooks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-cooks-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cooks-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.15: Cook’s distance in function of observation number.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>
<p>Once we observed that an observation is influential, the so-called <em>DFBETAs</em> can be used to determine on which regression coefficient(s) exactly it exercises its large influence. The DFBETAs of observation <span class="math inline">\(i\)</span> are a diagnostic measure for the influence of that observation <em>on each regression coefficient separately</em>, contrary to Cook’s distance which evaluates the influence on all coefficients simultaneously. In particular, the DFBETA for the <span class="math inline">\(i^{th}\)</span> observation and <span class="math inline">\(j^{th}\)</span> coefficient is obtained by comparing the <span class="math inline">\(j^{th}\)</span> coefficient <span class="math inline">\(\hat{\beta}_j\)</span> with the coefficient <span class="math inline">\(\hat{\beta}_{j(i)}\)</span> from the regression model that is fitted without including the <span class="math inline">\(i^{th}\)</span> observation in the analysis: <span class="math display">\[
    \textrm{DFBETA}_{j(i)}=\frac{\hat{\beta}_{j}-\hat{\beta}_{j(i)}}{\textrm{SD}(\hat{\beta}_{j})}.
\]</span> From this expression it follows that the sign of the DFBETA for observation <span class="math inline">\(i\)</span> indicates whether omitting that observation from the analysis causes an increase (DFBETA<span class="math inline">\(&lt;0\)</span>) or decrease (DFBETA<span class="math inline">\(&gt;0\)</span>) in the corresponding coefficient. A DFBETA is called extreme if it exceeds 1 in small to medium-sized datasets or <span class="math inline">\(2/\sqrt{n}\)</span> in larger datasets.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Mineral composition vs growth
</div>
</div>
<div class="callout-body-container callout-body">
<p>We concluded that the first observation is influential on the regression analysis for this example. The DFBETAs in <a href="#fig-dfbetas" class="quarto-xref">Figure&nbsp;<span>2.16</span></a> show that it has a large influence on the interaction between phosphorus and residual ash. The corresponding coefficient observed in the regression analysis is -598 (SE 290). Using the expression of the DFBETA and the fact that its value is 2.16, we conclude that omitting the first observation will change the interaction between phosphorus and residual ash to approximately <span class="math display">\[
    -598-2.16\times 290=-1224.
\]</span> Because of this, as well as the fact that the interaction between phosphorus and residual ash was only marginally significant, we decide to remove the interaction from the model. This leads to the output given below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>m_needles_full_centered_adjusted <span class="ot">&lt;-</span> <span class="fu">lm</span>(</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    length <span class="sc">~</span> cnitrogen <span class="sc">+</span> cphosphorus <span class="sc">+</span> cpotassium <span class="sc">+</span> cresidu <span class="sc">+</span>  cphosphorus<span class="sc">:</span>cnitrogen, <span class="at">data =</span> needles_centered)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m_needles_full_centered_adjusted)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = length ~ cnitrogen + cphosphorus + cpotassium + 
    cresidu + cphosphorus:cnitrogen, data = needles_centered)

Residuals:
    Min      1Q  Median      3Q     Max 
-48.540 -26.313   6.115  16.557  67.602 

Coefficients:
                      Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)             185.20       9.52  19.454 1.83e-14 ***
cnitrogen                99.40      23.40   4.247 0.000395 ***
cphosphorus             229.46     162.44   1.413 0.173167    
cpotassium              128.84      44.21   2.914 0.008574 ** 
cresidu                  23.51      36.09   0.651 0.522186    
cnitrogen:cphosphorus   661.50     370.78   1.784 0.089595 .  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 36.05 on 20 degrees of freedom
Multiple R-squared:  0.886, Adjusted R-squared:  0.8575 
F-statistic: 31.09 on 5 and 20 DF,  p-value: 8.924e-09</code></pre>
</div>
</div>
<p><a href="#fig-cooks-distance-adjusted" class="quarto-xref">Figure&nbsp;<span>2.17</span></a> confirms that there is now no longer a single observation that has an outsize influence on the results of the obtained model.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">dfbetas</span>(m_needles_full_centered)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(d[<span class="dv">1</span>, ],</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Parameter number"</span>,</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"DFBETA"</span>,</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"DFBETAs for observation 1"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-dfbetas" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-dfbetas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-dfbetas-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-dfbetas-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.16: DFBETAs for the first observation in function of the coefficient number.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Please remark that now the influence of residual ash on tree length has become insignificant and that in a next step this parameter will have to be removed from the model.</p>
<div class="cell" data-layout-align="center">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">cooks.distance</span>(m_needles_full_centered_adjusted),</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Observation"</span>,</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Cook's distance"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-cooks-distance-adjusted" class="quarto-figure quarto-figure-center quarto-float anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cooks-distance-adjusted-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression_files/figure-html/fig-cooks-distance-adjusted-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cooks-distance-adjusted-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2.17: Cook’s distance in function of observation number after removing the interaction between phosphorus and residual ash.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
</div>


</section>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>In practice we seldom know for sure (unless in randomised studies) if a certain variable <span class="math inline">\(C\)</span> is the only confounder for the association between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; often there can be unmeasured confounders that are not included in the dataset and for which it thus is also impossible to correct.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>The F-statistic in the regression output always gives the result for a test of the null hypothesis that the regression parameters for all predictors are zero (in other words, that none of the predictors is associated with the outcome) versus the alternative that at least 1 predictor is associated with the outcome.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

<p>These course notes are made available under the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons BY-NC-SA 4.0</a> license.</p></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./pca.html" class="pagination-link" aria-label="Principal component analysis">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Principal component analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>